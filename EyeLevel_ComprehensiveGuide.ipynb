{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e6hyGTplm9eu"
   },
   "source": [
    "# EyeLevel - A Comprehensive Guide\n",
    "*Updated 2024-12-11*\n",
    "\n",
    "This notebook is designed to help you use and fully understand EyeLevel's tools. For support feel free to either contact support@eyelevel.ai (general technical support).\n",
    "\n",
    "---\n",
    "\n",
    "## What is EyeLevel?\n",
    "\n",
    "EyeLevel is a set of unified technologies which are designed to allow you to parse and search through documents. This can be used in many applications, including:\n",
    "- Finding references within a large document set\n",
    "- Performing retreival augmented generation\n",
    "- Reformatting visually dense documents into a useful textual representation\n",
    "\n",
    "Eyelevel has two core technologies: GroundX and X-Ray.\n",
    "\n",
    "X-Ray is a modern take on document parsing: it uses a variety of computer vision and natural language processing techniques to turn documents (even those with complex formatting,) into a textual representation we call a \"semantic object\". Semantic objects contain key information about the document, sections of the document, and elements within the document in order to provide highly contextualized and useful representations of the source material.\n",
    "\n",
    "GroundX uses the semantic objects created by X-Ray to perform search. You can put a natural language question into GroundX and you'll get back a list of semantic objects, generated with X-Ray based on your documents, which are relevent to your question.\n",
    "\n",
    "## How does X-Ray work?\n",
    "\n",
    "We created a fine tuned vision model which is specifically designed to identify key elements within documents. We observe a variety of element types, but predominately concern ourselves with text, tables, and graphical figures. Once these elements have been identified they are extracted from the document and sent to a pipeliene depending on the type of element. Text is simply extracted while tables and images are grounded within a textual representation via fine tuned multimodal LLMs.\n",
    "\n",
    "Once all elements within a document are identified, extracted, and grounded textually, X-Ray constructs a summarization on a document and section level based on the extracted textual representations. This allows X-Ray to create a representation of the greater document context, which is used to build semantic objects.\n",
    "\n",
    "We use extracted text from the elements, as well as summary level information, to identify key ideas within the document. These ideas might encompass one or many extracted elements. We use the extracted data to construct a template of key information which needs to be filled in order to fully describe the identified ideas within the document.\n",
    "\n",
    "Once the document has been devided into ideas, and templates including what is needed to describe those ideas are generated, the templates are filled out via yet another fine tuned LLM. This, ultimately, is what becomes a semantic object. All models used in this process exist within EyeLevel's cloud, and can be deployed to a VPC as an atomic unit.\n",
    "\n",
    "## How does GroundX work?\n",
    "\n",
    "Because X-Ray creates highly queryable semantic objects, GroundX search does not use the traditional cosine-similarity flavor of vector search common in many similar retreival systems. Rather, GroundX employs a customized textual search strategy built on top of Apache Lucene, Lucene being designed for indexing and searching textual data. We employ a configured variety of Apache Lucene enabled search which is specifically designed to be maximally compatible with the semantic objects output by X-Ray.\n",
    "\n",
    "The validity of this approach is supported [in literature](https://arxiv.org/pdf/2308.14963) and also has a variety of practical benifits which allow for the optimization of GroundX on a case by case basis with minimal overhead.\n",
    "\n",
    "There's a lot of nitty gritty engineering that goes into this, which is the cumulative experience of eyelevel working with numerous companies across a diverse spread of documents. What we settled on is a complex multi-field filter and search which prioritizes certain elements in the semantic object, and certain tokens within those elements.\n",
    "\n",
    "## The Workflow\n",
    "\n",
    "All of eyelevels technologies (including X-Ray) can be accessed via the GroundX SDK, which is essentially a collection of language specific implementations and CURL accessible API endpoints. The documentation for the API can be found here:\n",
    "\n",
    "https://documentation.eyelevel.ai/reference/\n",
    "\n",
    "The most fundamental component of organization within GroundX is the bucket, which is used to store documents. When you upload a document to a bucket it will trigger X-Ray parsing, and the result will be stored on the bucket for later querying. The semantic objects which X-Ray creates are ultimately what is stored in a bucket.\n",
    "\n",
    "Projects are collections of buckets, allowing you to search between multiple buckets. This can allow you to organize information across buckets, and aggregate that information for specific use cases.\n",
    "\n",
    "Buckets and Projects can be searched against based on a natural language query. GroundX will search for the most relevent semantic objects which match your query and return them. GroundX will also construct a recomended text block which aggregates information from the most relevent retreived semantic objects. This is designed to be injected into a language model, enabling RAG esque qorkflows. We'll explore, in depth, the results of search later in the notebook.\n",
    "\n",
    "## Optimizing for Your Documents\n",
    "\n",
    "While EyeLevel's products are designed to work out of the box on arbitrary human documents, in reality it's impossible to make a single unified system that is perfect in every use case. One of the core ideas of both X-Ray and GroundX is an element of configurability: We can fine tune computer vision models on your documents, we can adjust templating to match your needs, and we can modify our search system based on your specific requirments. We also have a depth of experience in analyzing and testing the performance of RAG systems in real world use cases. The takeaway is that X-Ray + GroundX allows you to acheive state of the art performance out of the box on a wide range of common document types, and can be tailored to perform exelently to your documents if necessary.\n",
    "\n",
    "## On-Prem\n",
    "GroundX has both hosted and kubernetes deployable versions. If you want to use GroundX in a secure environment, and do RAG without any external communication, check out the [GroundX On-Prem Repo](https://github.com/eyelevelai/groundx-on-prem)\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AuIlpR589Y8t"
   },
   "source": [
    "# Creating an EyeLevel Account And Registering an API Key\n",
    "\n",
    "You can create an account here:\n",
    "\n",
    "https://dashboard.eyelevel.ai/auth/register\n",
    "\n",
    "Once you have an account setup, you can navigate here to setup an API key:\n",
    "\n",
    "https://dashboard.eyelevel.ai/apikey\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: python-dotenv in /Users/danielwarfield/Library/Python/3.9/lib/python/site-packages (1.0.1)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: OpenAI in /Users/danielwarfield/Library/Python/3.9/lib/python/site-packages (1.57.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/danielwarfield/Library/Python/3.9/lib/python/site-packages (from OpenAI) (0.28.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/danielwarfield/Library/Python/3.9/lib/python/site-packages (from OpenAI) (4.12.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/danielwarfield/Library/Python/3.9/lib/python/site-packages (from OpenAI) (2.10.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/danielwarfield/Library/Python/3.9/lib/python/site-packages (from OpenAI) (4.7.0)\n",
      "Requirement already satisfied: tqdm>4 in /Users/danielwarfield/Library/Python/3.9/lib/python/site-packages (from OpenAI) (4.67.1)\n",
      "Requirement already satisfied: sniffio in /Users/danielwarfield/Library/Python/3.9/lib/python/site-packages (from OpenAI) (1.3.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/danielwarfield/Library/Python/3.9/lib/python/site-packages (from OpenAI) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/danielwarfield/Library/Python/3.9/lib/python/site-packages (from OpenAI) (0.8.2)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/danielwarfield/Library/Python/3.9/lib/python/site-packages (from anyio<5,>=3.5.0->OpenAI) (3.10)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/danielwarfield/Library/Python/3.9/lib/python/site-packages (from anyio<5,>=3.5.0->OpenAI) (1.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/danielwarfield/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->OpenAI) (1.0.7)\n",
      "Requirement already satisfied: certifi in /Users/danielwarfield/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->OpenAI) (2024.8.30)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/danielwarfield/Library/Python/3.9/lib/python/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->OpenAI) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/danielwarfield/Library/Python/3.9/lib/python/site-packages (from pydantic<3,>=1.9.0->OpenAI) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /Users/danielwarfield/Library/Python/3.9/lib/python/site-packages (from pydantic<3,>=1.9.0->OpenAI) (2.27.1)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: groundx in /Users/danielwarfield/Library/Python/3.9/lib/python/site-packages (2.0.29)\n",
      "Requirement already satisfied: requests>=2.4.0 in /Users/danielwarfield/Library/Python/3.9/lib/python/site-packages (from groundx) (2.32.3)\n",
      "Requirement already satisfied: aiohttp>=3.8.0 in /Users/danielwarfield/Library/Python/3.9/lib/python/site-packages (from groundx) (3.11.10)\n",
      "Requirement already satisfied: typing_extensions>=4.0.0 in /Users/danielwarfield/Library/Python/3.9/lib/python/site-packages (from groundx) (4.12.2)\n",
      "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /Users/danielwarfield/Library/Python/3.9/lib/python/site-packages (from groundx) (2.27.1)\n",
      "Requirement already satisfied: httpx>=0.21.2 in /Users/danielwarfield/Library/Python/3.9/lib/python/site-packages (from groundx) (0.28.1)\n",
      "Requirement already satisfied: pydantic>=1.9.2 in /Users/danielwarfield/Library/Python/3.9/lib/python/site-packages (from groundx) (2.10.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/danielwarfield/Library/Python/3.9/lib/python/site-packages (from aiohttp>=3.8.0->groundx) (1.3.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/danielwarfield/Library/Python/3.9/lib/python/site-packages (from aiohttp>=3.8.0->groundx) (0.2.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/danielwarfield/Library/Python/3.9/lib/python/site-packages (from aiohttp>=3.8.0->groundx) (2.4.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/danielwarfield/Library/Python/3.9/lib/python/site-packages (from aiohttp>=3.8.0->groundx) (1.18.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/danielwarfield/Library/Python/3.9/lib/python/site-packages (from aiohttp>=3.8.0->groundx) (1.5.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /Users/danielwarfield/Library/Python/3.9/lib/python/site-packages (from aiohttp>=3.8.0->groundx) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/danielwarfield/Library/Python/3.9/lib/python/site-packages (from aiohttp>=3.8.0->groundx) (24.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/danielwarfield/Library/Python/3.9/lib/python/site-packages (from aiohttp>=3.8.0->groundx) (6.1.0)\n",
      "Requirement already satisfied: anyio in /Users/danielwarfield/Library/Python/3.9/lib/python/site-packages (from httpx>=0.21.2->groundx) (4.7.0)\n",
      "Requirement already satisfied: idna in /Users/danielwarfield/Library/Python/3.9/lib/python/site-packages (from httpx>=0.21.2->groundx) (3.10)\n",
      "Requirement already satisfied: certifi in /Users/danielwarfield/Library/Python/3.9/lib/python/site-packages (from httpx>=0.21.2->groundx) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/danielwarfield/Library/Python/3.9/lib/python/site-packages (from httpx>=0.21.2->groundx) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/danielwarfield/Library/Python/3.9/lib/python/site-packages (from httpcore==1.*->httpx>=0.21.2->groundx) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/danielwarfield/Library/Python/3.9/lib/python/site-packages (from pydantic>=1.9.2->groundx) (0.7.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/danielwarfield/Library/Python/3.9/lib/python/site-packages (from requests>=2.4.0->groundx) (2.2.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/danielwarfield/Library/Python/3.9/lib/python/site-packages (from requests>=2.4.0->groundx) (3.4.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/danielwarfield/Library/Python/3.9/lib/python/site-packages (from anyio->httpx>=0.21.2->groundx) (1.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/danielwarfield/Library/Python/3.9/lib/python/site-packages (from anyio->httpx>=0.21.2->groundx) (1.3.1)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /Users/danielwarfield/Library/Python/3.9/lib/python/site-packages (4.47.0)\n",
      "Requirement already satisfied: requests in /Users/danielwarfield/Library/Python/3.9/lib/python/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/danielwarfield/Library/Python/3.9/lib/python/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/danielwarfield/Library/Python/3.9/lib/python/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /Users/danielwarfield/Library/Python/3.9/lib/python/site-packages (from transformers) (0.26.5)\n",
      "Requirement already satisfied: filelock in /Users/danielwarfield/Library/Python/3.9/lib/python/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/danielwarfield/Library/Python/3.9/lib/python/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/danielwarfield/Library/Python/3.9/lib/python/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/danielwarfield/Library/Python/3.9/lib/python/site-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/danielwarfield/Library/Python/3.9/lib/python/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/danielwarfield/Library/Python/3.9/lib/python/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/danielwarfield/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/danielwarfield/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/danielwarfield/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/danielwarfield/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/danielwarfield/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/danielwarfield/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (2.2.3)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /Users/danielwarfield/Library/Python/3.9/lib/python/site-packages (2.5.1)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.20.1-cp39-cp39-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.8 MB 3.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: networkx in /Users/danielwarfield/Library/Python/3.9/lib/python/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: filelock in /Users/danielwarfield/Library/Python/3.9/lib/python/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/danielwarfield/Library/Python/3.9/lib/python/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: jinja2 in /Users/danielwarfield/Library/Python/3.9/lib/python/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Users/danielwarfield/Library/Python/3.9/lib/python/site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/danielwarfield/Library/Python/3.9/lib/python/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/danielwarfield/Library/Python/3.9/lib/python/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /Users/danielwarfield/Library/Python/3.9/lib/python/site-packages (from torchvision) (2.0.2)\n",
      "Collecting pillow!=8.3.*,>=5.3.0\n",
      "  Downloading pillow-11.0.0-cp39-cp39-macosx_11_0_arm64.whl (3.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0 MB 14.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /Users/danielwarfield/Library/Python/3.9/lib/python/site-packages (from jinja2->torch) (3.0.2)\n",
      "Installing collected packages: pillow, torchvision\n",
      "Successfully installed pillow-11.0.0 torchvision-0.20.1\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install python-dotenv\n",
    "!pip3 install OpenAI\n",
    "!pip3 install groundx\n",
    "#for suplamentary demo\n",
    "!pip3 install transformers\n",
    "!pip3 install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_PkmpBoJm82n"
   },
   "outputs": [],
   "source": [
    "\"\"\"Setting up API Keys\n",
    "\"\"\"\n",
    "is_google_secret = False\n",
    "is_env = True\n",
    "\n",
    "if is_google_secret:\n",
    "    #if your api key is stored in the colab seceret manager\n",
    "    from google.colab import userdata\n",
    "    import os\n",
    "    from openai import OpenAI\n",
    "\n",
    "    api_key = userdata.get('GROUNDX_API_KEY')\n",
    "\n",
    "    OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
    "    os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "\n",
    "elif is_env:\n",
    "    #using a local .env file\n",
    "    import os\n",
    "    from dotenv import load_dotenv\n",
    "\n",
    "    load_dotenv()\n",
    "\n",
    "    api_key = os.getenv('GROUNDX_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n774OOB6-xZD"
   },
   "source": [
    "# The Python SDK\n",
    "Interfacing with both X-Ray and GroundX can be done via [The Python GroundX SDK](https://pypi.org/project/groundx-python-sdk/). There's also a [node package](https://www.jsdelivr.com/package/npm/groundx-typescript-sdk) which exposes equivilent javascript functionality.\n",
    "\n",
    "Currently GroundX and X-Ray exist as a series of endpoints which we'll be exploring in this notebook. Documentation around those endpoints can be found here:\n",
    "\n",
    "https://documentation.eyelevel.ai/reference\n",
    "\n",
    "In the near future these endpoints will soon be abstracted into language specific implementations of core functionality. For now we'll be working directly with the exposed API endpoints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LxkuojN8AcAc"
   },
   "source": [
    "# Authenticating\n",
    "To get set up in python simply import the module and create an instance of the GroundX client with your API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "uDzmJQr_ADxl"
   },
   "outputs": [],
   "source": [
    "from groundx import GroundX\n",
    "client = GroundX(\n",
    "  api_key=api_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KbU8unIWW7Rb"
   },
   "source": [
    "# Creating a Bucket\n",
    "Buckets can either be created through [the dashboard](https://dashboard.eyelevel.ai/home) by selecting the `+ New Bucket` button, or via the api via the [create_bucket endpoint](https://documentation.eyelevel.ai/reference/Buckets/Bucket_create).\n",
    "\n",
    "Here we'll create a bucket called demo_bucket.\n",
    "\n",
    "Buckets are uniquely identified by a bucket_id which is returned upon completion of the endpoint. We'll use this bucket_id to upload documents and search against our bucket.\n",
    "\n",
    "The body of the response is formatted thus:\n",
    "```\n",
    "body={'bucket': {'bucketId': ____, 'name': ____}}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q7T4fZsBW7Jd",
    "outputId": "7972bf72-0c10-4615-f5ad-8cdeb8ce387f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created bucket 13367\n"
     ]
    }
   ],
   "source": [
    "response = client.buckets.create(\n",
    "    name=\"demo_bucket\"\n",
    ")\n",
    "bucket_id = response.bucket.bucket_id\n",
    "print(f'Created bucket {bucket_id}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m8vnAIgIRbr4"
   },
   "source": [
    "# Uploading Documents\n",
    "Now that we have a bucket we can upload documents to that bucket. Recall that this triggers X-Ray to parse the documents so our bucket will be populated with a bunch of semantic objects.\n",
    "\n",
    "X-Ray supports the following document types:\n",
    "```\n",
    "txt, docx, pptx, xlsx, pdf, png, jpg, csv, tsv, json\n",
    "```\n",
    "The primary use case of eyelevel products is in understanding complex human documents, so we'll use a PDF for this example. Specifically, we'll use [this document](https://arxiv.org/pdf/2110.11822), which is an academic paper with complex textual formatting and graphical figures.\n",
    "\n",
    "When using the `upload_local` endpoint you'll get a response with the flavor of\n",
    "\n",
    "```\n",
    "{'ingest': {'processId': ____, 'status': 'queued'}})\n",
    "```\n",
    "\n",
    "Once you upload a set of documents it triggers X-Ray to begin processing the documents. This can be observed by using the `processId`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "y2biMJzyaKz9"
   },
   "outputs": [],
   "source": [
    "from groundx import Document\n",
    "\n",
    "doc_path = '2110.11822v2.pdf'\n",
    "\n",
    "#uploading document\n",
    "response = client.ingest(\n",
    "    documents=[\n",
    "      Document(\n",
    "        bucket_id=bucket_id,\n",
    "        file_name=doc_path,\n",
    "        file_path=doc_path,\n",
    "        file_type='pdf'\n",
    "      )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_id = response.ingest.process_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w9pPbSr1jgBz"
   },
   "source": [
    "# Tracking X-Ray Progress\n",
    "\n",
    "We can poll the processId via the [get_processing_status_by_id](https://documentation.eyelevel.ai/reference/Documents/Document_getProcessingStatusById) endpoint, which will tell us if our documents are in one of four states.\n",
    "```\n",
    "cancelled, complete, errors, processing\n",
    "```\n",
    "\n",
    "The structure of the response obeys the following schema:\n",
    "```\n",
    "{\n",
    "  \"ingest\": {\n",
    "    \"processId\": \"9e0ad09b-5150-48c0-aded-707587048fd9\",\n",
    "    \"progress\": {\n",
    "      \"cancelled\": {\n",
    "        \"documents\": [\n",
    "          {\n",
    "            <document info>\n",
    "          }\n",
    "        ],\n",
    "        \"total\": 0\n",
    "      },\n",
    "      \"complete\": {\n",
    "        \"documents\": [\n",
    "          {\n",
    "            <document info>\n",
    "          }\n",
    "        ],\n",
    "        \"total\": 0\n",
    "      },\n",
    "      \"errors\": {\n",
    "        \"documents\": [\n",
    "          {\n",
    "            <document info>\n",
    "          }\n",
    "        ],\n",
    "        \"total\": 0\n",
    "      },\n",
    "      \"processing\": {\n",
    "        \"documents\": [\n",
    "          {\n",
    "            <document info>\n",
    "          }\n",
    "        ],\n",
    "        \"total\": 0\n",
    "      }\n",
    "    },\n",
    "    \"status\": \"queued\",\n",
    "```\n",
    "\n",
    "where `<document info>` might look like the following:\n",
    "```\n",
    "{\"bucketId\": 0,\n",
    "\"documentId\": \"4704590c-004e-410d-adf7-acb7ca0a7052\",\n",
    "\"fileName\": \"string\",\n",
    "\"fileSize\": \"1.4MB\",\n",
    "\"fileType\": \"txt\",\n",
    "\"processId\": \"9e0ad09b-5150-48c0-aded-707587048fd9\",\n",
    "\"searchData\": {},\n",
    "\"sourceUrl\": \"http://example.com\",\n",
    "\"status\": \"queued\",\n",
    "\"statusMessage\": \"string\",\n",
    "\"xrayUrl\": \"http://example.com\"}\n",
    "```\n",
    "\n",
    "This can be used for a variety of status checks depending on the application. For now, because we're only uploading a single document for testing purposes, I'll just poll this endpoing every 10 seconds to see if our document is done by checking the status of the cumulative process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gt4wwycki9Qu",
    "outputId": "acb76491-3d3c-4d48-e256-f4c0f5d74be6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "while True:\n",
    "\n",
    "    response = client.documents.get_processing_status_by_id(\n",
    "        process_id=process_id\n",
    "    )\n",
    "\n",
    "    if response.ingest.status == 'complete':\n",
    "        print('done!')\n",
    "        break\n",
    "\n",
    "    print('still processing...')\n",
    "    time.sleep(10)\n",
    "\n",
    "#getting the document id for the next section.\n",
    "doc_id = response.ingest.progress.complete.documents[0].document_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t6MMwevny0Hl"
   },
   "source": [
    "# Viewing X-Ray parse results\n",
    "In the previous section we got the document_id from the upload process. We can use that to get the URL where the X-Ray data is exposed (as a JSON object) then explore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "EoIICPVfmYP8"
   },
   "outputs": [],
   "source": [
    "#getting the URL of x-ray parsing\n",
    "response = client.documents.get(\n",
    "    document_id=doc_id\n",
    ")\n",
    "x_ray_url = response.document.xray_url\n",
    "\n",
    "#getting x-ray data\n",
    "import urllib.request, json\n",
    "with urllib.request.urlopen(x_ray_url) as url:\n",
    "    x_ray_data = json.loads(url.read().decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 181
    },
    "id": "DfivrPiaIsrq",
    "outputId": "c9d96a77-b1b8-4e00-f91f-99e9d5ab5a47"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This document describes the environmental impacts of artificial intelligence (AI) solutions, particularly focusing on their life cycle assessment and the balance between their positive and negative effects. It involves researchers from various French universities and research institutions, including Univ. Paris-Saclay, Univ. Aix-Marseille, Univ. Bordeaux, and Université Grenoble Alpes. The document, dated April 21, 2022, examines the energy consumption and greenhouse gas emissions associated with AI, especially deep learning, and the broader environmental implications beyond just carbon footprint. It reviews existing methodologies for assessing these impacts and proposes a comprehensive life cycle assessment approach to evaluate AI services' environmental value. The purpose is to highlight the need for a holistic evaluation of AI's environmental costs and benefits, emphasizing the importance of considering both direct and indirect effects.\\n\\nKeywords: AI environmental impact, life cycle assessment, deep learning, greenhouse gas emissions, AI for Green, energy consumption, carbon footprint, Univ. Paris-Saclay, Univ. Aix-Marseille, Univ. Bordeaux, Université Grenoble Alpes, 2022.\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"X-Ray summarization of the entire document\n",
    "\"\"\"\n",
    "x_ray_data['fileSummary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tCrDSQFlIvtC",
    "outputId": "8479983f-6368-48e5-8758-3d8b641bf8c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Type: pdf\n",
      "Language:  English\n",
      "Keywords:  2110.11822v2.pdf,AI environmental impact, artificial intelligence life cycle, AI energy consumption, deep learning emissions, greenhouse gas AI, AI carbon footprint, environmental assessment AI, AI sustainability, Univ. Paris-Saclay AI research, Univ. Aix-Marseille AI study, Univ. Bordeaux AI analysis, Université Grenoble Alpes AI project, April 21 2022 AI document, AI environmental value, AI positive negative effects, AI holistic evaluation, AI direct indirect effects, AI environmental methodologies, AI service assessment, AI research France, 2110.11822v2, AI environmental balance, AI ecological impact, AI life cycle approach.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"X-Ray provides some generally useful data about the document\n",
    "\"\"\"\n",
    "print('File Type:',x_ray_data['fileType'])\n",
    "print('Language: ',x_ray_data['language'])\n",
    "print('Keywords: ',x_ray_data['fileKeywords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q8M8qmTYKQKc",
    "outputId": "36c2ad1e-955b-44ea-f5fe-059c73ec2ee6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boundingBoxes': [{'bottomRightX': 1091,\n",
       "   'bottomRightY': 486,\n",
       "   'pageNumber': 1,\n",
       "   'topLeftX': 138,\n",
       "   'topLeftY': 319}],\n",
       " 'chunk': '24t9xe-0',\n",
       " 'contentType': ['table'],\n",
       " 'json': [{'description': 'List of authors and their affiliations',\n",
       "   'main_headers': ['Name', 'Affiliation', 'Location'],\n",
       "   'table_number': 'Missing',\n",
       "   'table_title': 'Missing'},\n",
       "  {'affiliation': 'Univ. Paris-Saclay, LIMSI, CNRS, ENSIIE',\n",
       "   'location': 'Orsay, France',\n",
       "   'name': 'Anne-Laure Ligozat'},\n",
       "  {'affiliation': 'Univ. Aix-Marseille, CNRS, Centrale Marseille',\n",
       "   'location': 'Marseille, France',\n",
       "   'name': 'Julien Lefèvre'},\n",
       "  {'affiliation': 'Univ. Bordeaux, Bordeaux INP, CNRS, Laboratoire LaBRI',\n",
       "   'location': 'Talence, France',\n",
       "   'name': 'Aurélie Bugeau'},\n",
       "  {'affiliation': 'Universite Grenoble Alpes, VERIMAG',\n",
       "   'location': 'Grenoble, France',\n",
       "   'name': 'Jacques Combaz'}],\n",
       " 'multimodalUrl': 'https://upload.eyelevel.ai/layout/raw/prod/b2e8d0f1-0322-46f5-96c1-33de449a1011/c6e9873a-9b71-428b-afeb-bf0a4c2e3229/table-1-0.jpg',\n",
       " 'narrative': ['The first author is Anne-Laure Ligozat from Univ. Paris-Saclay, located in Orsay, France. The second author is Julien Lefèvre from Univ. Aix-Marseille, located in Marseille, France. The third author is Aurélie Bugeau from Univ. Bordeaux, located in Talence, France. The fourth author is Jacques Combaz from Universite Grenoble Alpes, located in Grenoble, France.'],\n",
       " 'pageNumbers': [1],\n",
       " 'sectionSummary': \"The document explores the environmental impacts of artificial intelligence (AI), particularly focusing on life cycle assessment (LCA) of AI solutions. It involves researchers from French universities, including Univ. Paris-Saclay, Univ. Aix-Marseille, Univ. Bordeaux, and Université Grenoble Alpes. The main theme is the dual nature of AI's environmental impact, where AI is both a tool for addressing environmental issues and a contributor to greenhouse gas emissions due to its energy-intensive processes. The document reviews existing methodologies for assessing AI's environmental impacts and proposes a comprehensive LCA approach to evaluate AI services. It emphasizes the importance of considering both direct and indirect environmental effects, including energy consumption, carbon footprint, and broader ecological impacts. The purpose is to provide a holistic evaluation framework for AI's environmental costs and benefits, especially in the context of AI for Green initiatives.\\n\\nKeywords: AI environmental impact, life cycle assessment, deep learning emissions, greenhouse gas AI, AI carbon footprint, AI sustainability, Univ. Paris-Saclay, Univ. Aix-Marseille, Univ. Bordeaux, Université Grenoble Alpes, AI for Green, environmental assessment AI, AI ecological impact, AI energy consumption, AI research France, 2110.11822v2, AI environmental balance, AI holistic evaluation.\",\n",
       " 'suggestedText': '{\"table_title\":\"Missing\",\"table_number\":\"Missing\",\"description\":\"List of authors and their affiliations\",\"main_headers\":[\"Name\",\"Affiliation\",\"Location\"]}\\n{\"name\":\"Anne-Laure Ligozat\",\"affiliation\":\"Univ. Paris-Saclay, LIMSI, CNRS, ENSIIE\",\"location\":\"Orsay, France\"}\\n{\"name\":\"Julien Lefèvre\",\"affiliation\":\"Univ. Aix-Marseille, CNRS, Centrale Marseille\",\"location\":\"Marseille, France\"}\\n{\"name\":\"Aurélie Bugeau\",\"affiliation\":\"Univ. Bordeaux, Bordeaux INP, CNRS, Laboratoire LaBRI\",\"location\":\"Talence, France\"}\\n{\"name\":\"Jacques Combaz\",\"affiliation\":\"Universite Grenoble Alpes, VERIMAG\",\"location\":\"Grenoble, France\"}\\n\\nThe first author is Anne-Laure Ligozat from Univ. Paris-Saclay, located in Orsay, France. The second author is Julien Lefèvre from Univ. Aix-Marseille, located in Marseille, France. The third author is Aurélie Bugeau from Univ. Bordeaux, located in Talence, France. The fourth author is Jacques Combaz from Universite Grenoble Alpes, located in Grenoble, France.',\n",
       " 'text': '\\t|\\t\\t|\\tAnne - Laure Ligozat\\t|\\t\\t|\\tJulien Lefèvre\\n\\t|\\tUniv . Paris - Saclay , LIMSI , CNRS , ENSIIE\\t|\\t\\t|\\tUniv . Aix - Marseille , CNRS , Centrale Marseille\\n\\t|\\tOrsay , France\\t|\\t\\t|\\tMarseille , France\\n\\t|\\tAurélie Bugeau\\t|\\t\\t|\\tJacques Combaz\\nUniv . Bordeaux , Bordeaux INP , CNRS , Laboratoire LaBRI\\t|\\t\\t|\\t\\t|\\tUniversite Grenoble Alpes , VERIMAG\\nTalence , France\\t|\\t\\t|\\t\\t|\\tGrenoble , France'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Semantic object Exploration\n",
    "Semantic objects can exist on one or multiple pages. In this object you can see\n",
    "the following:\n",
    " - A list of bounding boxes from items on the page(s) that contribute to the object\n",
    " - The type of content, in this case a paragraph (as apposed to a figure or table)\n",
    " - the page number(s) the semantic object exists within.\n",
    " - sectionSummary: summarizes the greater section the semantic object is within.\n",
    " This is designed to provide additional context to the semantic object.\n",
    " - suggestedText: is LLM rewritten text which is based on the extracted text and\n",
    " other section level and document level information.\n",
    " - text: The raw extracted textual data\n",
    "\"\"\"\n",
    "x_ray_data['chunks'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZjEwTXlaRt_Z",
    "outputId": "508afea0-1635-4f22-a914-6f446dc4dcdd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boundingBoxes': [{'bottomRightX': 1157,\n",
       "   'bottomRightY': 1253,\n",
       "   'pageNumber': 4,\n",
       "   'topLeftX': 665,\n",
       "   'topLeftY': 882}],\n",
       " 'chunk': 'cf0xmx-0',\n",
       " 'contentType': ['table'],\n",
       " 'json': [{'description': 'The table outlines the life cycle stages and unit processes for AI services, indicating whether each process is mandatory or recommended.',\n",
       "   'main_headers': ['Life Cycle Stage', 'Requirement'],\n",
       "   'table_title': 'Application to AI services of ITU recommendation'},\n",
       "  {'life_cycle_stage': 'A - Raw material acquisition',\n",
       "   'requirement': 'Mandatory'},\n",
       "  {'life_cycle_stage': 'B - Production',\n",
       "   'requirement': 'Devices production and assembly',\n",
       "   'status': 'Mandatory'},\n",
       "  {'life_cycle_stage': 'B - Production',\n",
       "   'requirement': 'Manufacturer support activities',\n",
       "   'status': 'Recommended'},\n",
       "  {'life_cycle_stage': 'B - Production',\n",
       "   'requirement': 'Production of support equipment',\n",
       "   'status': 'Mandatory'},\n",
       "  {'life_cycle_stage': 'B - Production',\n",
       "   'requirement': 'ICT-specific site construction',\n",
       "   'status': 'Recommended'},\n",
       "  {'life_cycle_stage': 'C - Use',\n",
       "   'requirement': 'Use of ICT equipment',\n",
       "   'status': 'Mandatory'},\n",
       "  {'life_cycle_stage': 'C - Use',\n",
       "   'requirement': 'Use of support equipment',\n",
       "   'status': 'Mandatory'},\n",
       "  {'life_cycle_stage': 'C - Use',\n",
       "   'requirement': 'Operator support activities',\n",
       "   'status': 'Recommended'},\n",
       "  {'life_cycle_stage': 'C - Use',\n",
       "   'requirement': 'Service provider support activities',\n",
       "   'status': 'Recommended'},\n",
       "  {'life_cycle_stage': 'D - End of life',\n",
       "   'requirement': 'Preparation of ICT goods for reuse',\n",
       "   'status': 'Mandatory'},\n",
       "  {'life_cycle_stage': 'D - End of life',\n",
       "   'requirement': 'Storage / disassembly / dismantling / crushing',\n",
       "   'status': 'Mandatory'}],\n",
       " 'multimodalUrl': 'https://upload.eyelevel.ai/layout/raw/prod/b2e8d0f1-0322-46f5-96c1-33de449a1011/c6e9873a-9b71-428b-afeb-bf0a4c2e3229/table-4-0.jpg',\n",
       " 'narrative': ['The following table contains the life cycle stages and unit processes for AI services, indicating whether each process is mandatory or recommended. The stages include raw material acquisition, production, use, and end of life, with specific tasks such as devices production, support activities, and equipment use. Each task is marked as either mandatory or recommended, providing guidance on the necessary requirements for each stage.'],\n",
       " 'pageNumbers': [4],\n",
       " 'sectionSummary': \"The document explores the environmental impacts of artificial intelligence (AI), particularly focusing on life cycle assessment (LCA) of AI solutions. It involves researchers from French universities, including Univ. Paris-Saclay, Univ. Aix-Marseille, Univ. Bordeaux, and Université Grenoble Alpes. The main theme is the dual nature of AI's environmental impact, where AI is both a tool for addressing environmental issues and a contributor to greenhouse gas emissions due to its energy-intensive processes. The document reviews existing methodologies for assessing AI's environmental impacts and proposes a comprehensive LCA approach to evaluate AI services. It emphasizes the importance of considering both direct and indirect environmental effects, including energy consumption, carbon footprint, and broader ecological impacts. The purpose is to provide a holistic evaluation framework for AI's environmental costs and benefits, especially in the context of AI for Green initiatives.\\n\\nKeywords: AI environmental impact, life cycle assessment, deep learning emissions, greenhouse gas AI, AI carbon footprint, AI sustainability, Univ. Paris-Saclay, Univ. Aix-Marseille, Univ. Bordeaux, Université Grenoble Alpes, AI for Green, environmental assessment AI, AI ecological impact, AI energy consumption, AI research France, 2110.11822v2, AI environmental balance, AI holistic evaluation.\",\n",
       " 'suggestedText': '{\"table_title\":\"Application to AI services of ITU recommendation\",\"description\":\"The table outlines the life cycle stages and unit processes for AI services, indicating whether each process is mandatory or recommended.\",\"main_headers\":[\"Life Cycle Stage\",\"Requirement\"]}\\n\\n{\"life_cycle_stage\":\"A - Raw material acquisition\",\"requirement\":\"Mandatory\"}\\n{\"life_cycle_stage\":\"B - Production\",\"requirement\":\"Devices production and assembly\",\"status\":\"Mandatory\"}\\n{\"life_cycle_stage\":\"B - Production\",\"requirement\":\"Manufacturer support activities\",\"status\":\"Recommended\"}\\n{\"life_cycle_stage\":\"B - Production\",\"requirement\":\"Production of support equipment\",\"status\":\"Mandatory\"}\\n{\"life_cycle_stage\":\"B - Production\",\"requirement\":\"ICT-specific site construction\",\"status\":\"Recommended\"}\\n{\"life_cycle_stage\":\"C - Use\",\"requirement\":\"Use of ICT equipment\",\"status\":\"Mandatory\"}\\n{\"life_cycle_stage\":\"C - Use\",\"requirement\":\"Use of support equipment\",\"status\":\"Mandatory\"}\\n{\"life_cycle_stage\":\"C - Use\",\"requirement\":\"Operator support activities\",\"status\":\"Recommended\"}\\n{\"life_cycle_stage\":\"C - Use\",\"requirement\":\"Service provider support activities\",\"status\":\"Recommended\"}\\n{\"life_cycle_stage\":\"D - End of life\",\"requirement\":\"Preparation of ICT goods for reuse\",\"status\":\"Mandatory\"}\\n{\"life_cycle_stage\":\"D - End of life\",\"requirement\":\"Storage / disassembly / dismantling / crushing\",\"status\":\"Mandatory\"}\\n\\nThe following table contains the life cycle stages and unit processes for AI services, indicating whether each process is mandatory or recommended. The stages include raw material acquisition, production, use, and end of life, with specific tasks such as devices production, support activities, and equipment use. Each task is marked as either mandatory or recommended, providing guidance on the necessary requirements for each stage.',\n",
       " 'text': 'A - Raw material acquisition\\t|\\tMandatory\\nB Production\\nDevices production and assembly\\t|\\tMandatory\\nManufacturer support activities\\t|\\tRecommended\\nProduction of support equipment\\t|\\tMandatory\\nICT - specific site construction\\t|\\tRecommended\\nC - Use\\nUse of ICT equipment\\t|\\tMandatory\\nUse of support equipment\\t|\\tMandatory\\nOperator support activities\\t|\\tRecommended\\nService provider support activities\\t|\\tRecommended\\nD - End of life\\nPreparation of ICT goods for reuse Mandatory\\nStorage / disassembly / dismantling Mandatory\\n/ crushing'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Semantic object Exploration\n",
    "The previous example of a semantic object only contained textual information.\n",
    "Let's explore a table.\n",
    "\n",
    "As can be seen the content of this semantic object is similar to the one used\n",
    "to represent paragraph information, but with some key differences:\n",
    "- There's a json description of the data\n",
    "- There's a url to the image used to extract data\n",
    "- There is a narrative representation of the data\n",
    "\n",
    "Click the multimodal URL to renter the image!\n",
    "\n",
    "We've found that things like figures and tables often benifit from having\n",
    "both a JSON description of what content exists, as well as a narrative description\n",
    "to describe key elements.\n",
    "\"\"\"\n",
    "x_ray_data['chunks'][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dSLPgRhdWSn9",
    "outputId": "da1cb79e-9a67-4579-9e8a-c6d1eff89d46"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boundingBoxes': [{'bottomRightX': 801,\n",
       "   'bottomRightY': 651,\n",
       "   'pageNumber': 5,\n",
       "   'topLeftX': 473,\n",
       "   'topLeftY': 636}],\n",
       " 'chunk': '8q2f7z-14',\n",
       " 'contentType': ['paragraph'],\n",
       " 'pageNumbers': [5],\n",
       " 'sectionSummary': \"The document explores the environmental impacts of artificial intelligence (AI), particularly focusing on life cycle assessment (LCA) of AI solutions. It involves researchers from French universities, including Univ. Paris-Saclay, Univ. Aix-Marseille, Univ. Bordeaux, and Université Grenoble Alpes. The main theme is the dual nature of AI's environmental impact, where AI is both a tool for addressing environmental issues and a contributor to greenhouse gas emissions due to its energy-intensive processes. The document reviews existing methodologies for assessing AI's environmental impacts and proposes a comprehensive LCA approach to evaluate AI services. It emphasizes the importance of considering both direct and indirect environmental effects, including energy consumption, carbon footprint, and broader ecological impacts. The purpose is to provide a holistic evaluation framework for AI's environmental costs and benefits, especially in the context of AI for Green initiatives.\\n\\nKeywords: AI environmental impact, life cycle assessment, deep learning emissions, greenhouse gas AI, AI carbon footprint, AI sustainability, Univ. Paris-Saclay, Univ. Aix-Marseille, Univ. Bordeaux, Université Grenoble Alpes, AI for Green, environmental assessment AI, AI ecological impact, AI energy consumption, AI research France, 2110.11822v2, AI environmental balance, AI holistic evaluation.\",\n",
       " 'suggestedText': '( a ) Different tasks involved in an artificial intelligence (AI) service',\n",
       " 'text': '( a ) Different tasks involved in an AI service'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Semantic object Exploration\n",
    "Here's an example of a figure\n",
    "\n",
    "it has the same general structure as tables, but a different underlying pipeline\n",
    "in X-Ray was used to create this object. In being more complex visually than\n",
    "a table, the narrative representation is arguably more impactful\n",
    "\"\"\"\n",
    "x_ray_data['chunks'][9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mIxmEfr1ZdDC"
   },
   "source": [
    "# Searching\n",
    "Ok, we have a bunch of these semantic objects thanks to X-Ray, and they exist within GroundX buckets. Now we can run search via GroundX. Search will get us a list of semantic objects as well as some additional aggregate information.\n",
    "\n",
    "Within the search object you'll find:\n",
    " - count: the number of relevent semantic objects\n",
    " - query: the query used in search\n",
    " - results: a list of semantic objects. These are normal semantic objects, but they each have an additional \"score\" attribute which describes how well they align with the users query.\n",
    " - score: How relevent the top scoring semantic object is.\n",
    " - text: a formatted block of text which contains information from relevent chunks. This can be used as context in a RAG application.\n",
    "\n",
    "The list of semantic objects are just like the semantic objects previously discussed, but they each have a \"score\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "jVdOPjZNX3I6"
   },
   "outputs": [],
   "source": [
    "search_query = 'I need a diagram of the AI lifecycle'\n",
    "\n",
    "response = client.search.content(\n",
    "    id=bucket_id,\n",
    "    query=search_query\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cOJTea_4fpwm",
    "outputId": "fcbb295a-7cab-47f3-f675-a46648b85fbc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bounding_boxes': [BoundingBoxDetail(bottom_right_x=954.7816, bottom_right_y=1070.8883, page_number=5, top_left_x=317.81744, top_left_y=649.6449)],\n",
       " 'bucket_id': 13367,\n",
       " 'chunk_id': None,\n",
       " 'document_id': 'c6e9873a-9b71-428b-afeb-bf0a4c2e3229',\n",
       " 'file_name': '2110.11822v2.pdf',\n",
       " 'multimodal_url': 'https://upload.eyelevel.ai/layout/raw/prod/b2e8d0f1-0322-46f5-96c1-33de449a1011/c6e9873a-9b71-428b-afeb-bf0a4c2e3229/figure-5-0.jpg',\n",
       " 'page_images': ['https://upload.eyelevel.ai/layout/raw/prod/b2e8d0f1-0322-46f5-96c1-33de449a1011/c6e9873a-9b71-428b-afeb-bf0a4c2e3229/5.jpg'],\n",
       " 'score': 288.84952,\n",
       " 'search_data': None,\n",
       " 'source_url': 'https://upload.groundx.ai/prod/file/974d725e-e804-49f4-9792-de162e50a15c/c7dca033-104d-4bee-9a9a-15ed261187b6.pdf',\n",
       " 'suggested_text': '{\"figure_title\": \"Life Cycle Inventory of an AI Service\", \"figure_number\": 2, \"description\": \"Diagram illustrating the life cycle phases of an AI service and associated emissions.\", \"components\": [\"Production of devicei\", \"Use of devicei\", \"End of life of devicei\", \"Production of electricity\", \"Resources (metals, etc.)\"], \"relationships\": [{\"source\": \"Production of devicei\", \"target\": \"Use of devicei\", \"type\": \"flow\"}, {\"source\": \"Use of devicei\", \"target\": \"End of life of devicei\", \"type\": \"flow\"}, {\"source\": \"Production of electricity\", \"target\": \"Production of devicei\", \"type\": \"support\"}, {\"source\": \"Resources (metals, etc.)\", \"target\": \"Production of electricity\", \"type\": \"resource\"}, {\"source\": \"Production of devicei\", \"target\": \"Emissions\", \"type\": \"environmental impact\"}, {\"source\": \"Use of devicei\", \"target\": \"Emissions\", \"type\": \"environmental impact\"}, {\"source\": \"End of life of devicei\", \"target\": \"Emissions\", \"type\": \"environmental impact\"}]}\\n{\"element\": \"Production of devicei\", \"connected_to\": \"Use of devicei\", \"direction\": \"flows to\"}\\n{\"element\": \"Use of devicei\", \"connected_to\": \"End of life of devicei\", \"direction\": \"flows to\"}\\n{\"element\": \"Production of electricity\", \"connected_to\": \"Production of devicei\", \"type\": \"supporting resource\"}\\n{\"element\": \"Resources (metals, etc.)\", \"connected_to\": \"Production of electricity\", \"type\": \"resource\"}\\n{\"element\": \"Emissions\", \"related_to\": [\"Production of devicei\", \"Use of devicei\", \"End of life of devicei\"], \"type\": \"environmental impact\"}\\n\\nThe diagram represents the life cycle phases of an AI service, focusing on the production, use, and end-of-life stages of a device. It shows the flow of processes from the production of the device to its use and eventual end of life. The production of electricity is a supporting resource necessary for the production phase, and resources such as metals are required for electricity production. Emissions, including pollution and abiotic resource depletion, are associated with each phase of the device\\'s life cycle. The diagram highlights the environmental impacts at each stage, emphasizing the need to consider these factors in the life cycle assessment of AI services.',\n",
       " 'text': 'Emissions ( pollution , abiotic resources depletion ... )\\nProduction\\nof electricity\\nProduction\\nof devicei\\nUse\\n of devicei\\nEnd of life\\nof devicei\\nResources\\n ( metals , etc. )',\n",
       " 'fileKeywords': '2110.11822v2.pdf,AI environmental impact, artificial intelligence life cycle, AI energy consumption, deep learning emissions, greenhouse gas AI, AI carbon footprint, environmental assessment AI, AI sustainability, Univ. Paris-Saclay AI research, Univ. Aix-Marseille AI study, Univ. Bordeaux AI analysis, Université Grenoble Alpes AI project, April 21 2022 AI document, AI environmental value, AI positive negative effects, AI holistic evaluation, AI direct indirect effects, AI environmental methodologies, AI service assessment, AI research France, 2110.11822v2, AI environmental balance, AI ecological impact, AI life cycle approach.',\n",
       " 'json': [{'components': ['Production of devicei',\n",
       "    'Use of devicei',\n",
       "    'End of life of devicei',\n",
       "    'Production of electricity',\n",
       "    'Resources (metals, etc.)'],\n",
       "   'description': 'Diagram illustrating the life cycle phases of an AI service and associated emissions.',\n",
       "   'figure_number': 2,\n",
       "   'figure_title': 'Life Cycle Inventory of an AI Service',\n",
       "   'relationships': [{'source': 'Production of devicei',\n",
       "     'target': 'Use of devicei',\n",
       "     'type': 'flow'},\n",
       "    {'source': 'Use of devicei',\n",
       "     'target': 'End of life of devicei',\n",
       "     'type': 'flow'},\n",
       "    {'source': 'Production of electricity',\n",
       "     'target': 'Production of devicei',\n",
       "     'type': 'support'},\n",
       "    {'source': 'Resources (metals, etc.)',\n",
       "     'target': 'Production of electricity',\n",
       "     'type': 'resource'},\n",
       "    {'source': 'Production of devicei',\n",
       "     'target': 'Emissions',\n",
       "     'type': 'environmental impact'},\n",
       "    {'source': 'Use of devicei',\n",
       "     'target': 'Emissions',\n",
       "     'type': 'environmental impact'},\n",
       "    {'source': 'End of life of devicei',\n",
       "     'target': 'Emissions',\n",
       "     'type': 'environmental impact'}]},\n",
       "  {'connected_to': 'Use of devicei',\n",
       "   'direction': 'flows to',\n",
       "   'element': 'Production of devicei'},\n",
       "  {'connected_to': 'End of life of devicei',\n",
       "   'direction': 'flows to',\n",
       "   'element': 'Use of devicei'},\n",
       "  {'connected_to': 'Production of devicei',\n",
       "   'element': 'Production of electricity',\n",
       "   'type': 'supporting resource'},\n",
       "  {'connected_to': 'Production of electricity',\n",
       "   'element': 'Resources (metals, etc.)',\n",
       "   'type': 'resource'},\n",
       "  {'element': 'Emissions',\n",
       "   'related_to': ['Production of devicei',\n",
       "    'Use of devicei',\n",
       "    'End of life of devicei'],\n",
       "   'type': 'environmental impact'}],\n",
       " 'narrative': [\"The diagram represents the life cycle phases of an AI service, focusing on the production, use, and end-of-life stages of a device. It shows the flow of processes from the production of the device to its use and eventual end of life. The production of electricity is a supporting resource necessary for the production phase, and resources such as metals are required for electricity production. Emissions, including pollution and abiotic resource depletion, are associated with each phase of the device's life cycle. The diagram highlights the environmental impacts at each stage, emphasizing the need to consider these factors in the life cycle assessment of AI services.\"]}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exploring a retrieved chunk\n",
    "dict(response.search.results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "7IYS9A7yfsXh",
    "outputId": "8ef4ae3d-4ba9-410e-fe61-fa3900479a83"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The following text excerpts are from the same section of a document named \\'2110.11822v2.pdf\\':\\n\\nText excerpt from page number 5:\\n{\"figure_title\": \"Life Cycle Inventory of an AI Service\", \"figure_number\": 2, \"description\": \"Diagram illustrating the life cycle phases of an AI service and associated emissions.\", \"components\": [\"Production of devicei\", \"Use of devicei\", \"End of life of devicei\", \"Production of electricity\", \"Resources (metals, etc.)\"], \"relationships\": [{\"source\": \"Production of devicei\", \"target\": \"Use of devicei\", \"type\": \"flow\"}, {\"source\": \"Use of devicei\", \"target\": \"End of life of devicei\", \"type\": \"flow\"}, {\"source\": \"Production of electricity\", \"target\": \"Production of devicei\", \"type\": \"support\"}, {\"source\": \"Resources (metals, etc.)\", \"target\": \"Production of electricity\", \"type\": \"resource\"}, {\"source\": \"Production of devicei\", \"target\": \"Emissions\", \"type\": \"environmental impact\"}, {\"source\": \"Use of devicei\", \"target\": \"Emissions\", \"type\": \"environmental impact\"}, {\"source\": \"End of life of devicei\", \"target\": \"Emissions\", \"type\": \"environmental impact\"}]}\\n{\"element\": \"Production of devicei\", \"connected_to\": \"Use of devicei\", \"direction\": \"flows to\"}\\n{\"element\": \"Use of devicei\", \"connected_to\": \"End of life of devicei\", \"direction\": \"flows to\"}\\n{\"element\": \"Production of electricity\", \"connected_to\": \"Production of devicei\", \"type\": \"supporting resource\"}\\n{\"element\": \"Resources (metals, etc.)\", \"connected_to\": \"Production of electricity\", \"type\": \"resource\"}\\n{\"element\": \"Emissions\", \"related_to\": [\"Production of devicei\", \"Use of devicei\", \"End of life of devicei\"], \"type\": \"environmental impact\"}\\n\\nThe diagram represents the life cycle phases of an AI service, focusing on the production, use, and end-of-life stages of a device. It shows the flow of processes from the production of the device to its use and eventual end of life. The production of electricity is a supporting resource necessary for the production phase, and resources such as metals are required for electricity production. Emissions, including pollution and abiotic resource depletion, are associated with each phase of the device\\'s life cycle. The diagram highlights the environmental impacts at each stage, emphasizing the need to consider these factors in the life cycle assessment of AI services.\\n\\n\\nText excerpt from page number 5:\\n{\"figure title\":\"Life Cycle Inventory of an AI Service\",\"figure number\":2,\"description\":\"This diagram illustrates the processes involved in an AI service, including data acquisition, production, learning, and inference. It shows the flow of data and the devices used in each process.\",\"components\":[\"Data acquisition\",\"Data production\",\"Learning\",\"Data storage\",\"Inference\",\"AI enhanced application\"],\"relationships\":[{\"source\":\"Data acquisition\",\"target\":\"Data production\",\"type\":\"flow\"},{\"source\":\"Data production\",\"target\":\"Learning\",\"type\":\"flow\"},{\"source\":\"Learning\",\"target\":\"Data storage\",\"type\":\"flow\"},{\"source\":\"Data storage\",\"target\":\"Inference\",\"type\":\"flow\"},{\"source\":\"Inference\",\"target\":\"AI enhanced application\",\"type\":\"flow\"}]}\\n\\n{\"element\":\"Data acquisition\",\"connected_to\":\"Data production\",\"device\":\"device1 (sensors...)\",\"direction\":\"flows to\"}\\n{\"element\":\"Data production\",\"connected_to\":\"Learning\",\"device\":\"device2 (computer...)\",\"direction\":\"flows to\"}\\n{\"element\":\"Learning\",\"connected_to\":\"Data storage\",\"device\":\"device3 (supercomputer...)\",\"direction\":\"flows to\"}\\n{\"element\":\"Data storage\",\"connected_to\":\"Inference\",\"device\":\"device5 (hard drive...)\",\"direction\":\"flows to\"}\\n{\"element\":\"Inference\",\"connected_to\":\"AI enhanced application\",\"device\":\"device4 (mobile...)\",\"direction\":\"flows to\"}\\n\\nThe diagram represents the life cycle inventory of an AI service. It includes various processes such as data acquisition, data production, learning, data storage, and inference. Each process is associated with specific devices: data acquisition uses sensors, data production uses computers, learning uses supercomputers, data storage uses hard drives, and inference uses mobile devices. The flow of data starts from data acquisition, moving to data production, then to learning, followed by data storage, and finally to inference. The inference process supports AI-enhanced applications like electric vehicles and smart buildings. The diagram emphasizes the interconnectedness of these processes and the role of different devices in facilitating the AI service.\\n\\n\\nText excerpt from page number 6:\\n{\"figure_title\":\"Impact Assessment of AI Solutions\",\"figure_number\":1,\"description\":\"This diagram illustrates the total impact assessment for an AI application, highlighting the relationships between direct, second-order, and third-order impacts.\",\"components\":[\"LCA(M1)\",\"LCA(M2)\",\"LCA_AI(M2)\",\"3rd order impacts\",\"Direct impacts (AI service)\",\"2nd order impacts (Application)\"],\"trends\":[\"Positive and negative impacts indicated on the vertical axis\"],\"relationships\":[{\"source\":\"Direct impacts (AI service)\",\"target\":\"2nd order impacts (Application)\",\"type\":\"flow\"},{\"group\":\"LCA impacts\",\"elements\":[\"LCA(M1)\",\"LCA(M2)\",\"LCA_AI(M2)\"]}]}\\n{\"element\":\"LCA(M1)\",\"relationship\":{\"connected_to\":\"3rd order impacts\",\"type\":\"baseline assessment\"}}\\n{\"element\":\"LCA(M2)\",\"relationship\":{\"connected_to\":\"3rd order impacts\",\"type\":\"AI-enhanced assessment\"}}\\n{\"element\":\"LCA_AI(M2)\",\"relationship\":{\"type\":\"AI service specific assessment\"}}\\n{\"element\":\"3rd order impacts\",\"note\":\"ignored in our proposal\"}\\n{\"axis\":\"impact\",\"scale\":[\"negative impact\",\"positive impact\"],\"colors\":[\"red\",\"green\"]}\\n\\nThe diagram presents an impact assessment framework for AI solutions, focusing on life cycle assessments (LCA) for different phases. It includes components such as LCA(M1), which represents the baseline assessment without AI, and LCA(M2), which includes AI enhancements. LCA_AI(M2) is a specific assessment of the AI service itself. The diagram emphasizes the flow of impacts from direct AI service impacts to second-order application impacts. Third-order impacts are acknowledged but ignored in this proposal. The vertical axis illustrates a scale from negative to positive impacts, using red and green colors to denote the impact magnitude.\\n\\n\\nText excerpt from page number 3:\\nEven though Life Cycle Assessment (LCA) is widely used in many domains, it has rarely been applied to artificial intelligence (AI) services.\\n\\n3 Life Cycle Assessment of an AI Solution\\n\\nWhen it comes to quantifying the impacts of digital technologies, particularly AI technologies, several methodological choices arise that require a specific definition of the studied system. For instance, assessing the global impacts of the AI domain—if we could precisely define it—is not the same as assessing the impacts of an AI algorithm or service. The emerging field of AI\\'s impact quantification still lacks a common methodology and often focuses only on the Use phase of devices involved in an AI service. To perform meaningful quantification, we strongly suggest following the general framework of life cycle assessment (LCA, detailed in Section 3.2). We will show how it can be adapted to an AI service, such as a deep learning code used either alone or in a larger application.\\n\\nAI is part of the Information and Communication Technology (ICT) sector, and following the taxonomies from references [18, 19], its impacts can be divided into first-, second-, and third-order impacts. In this section, we focus only on first-order impacts, while we will discuss second and third orders in Sections 4 and 5.\\n\\nWe will use the term AI service for all the equipment (sensors, servers, etc.) used by the AI, and the term AI solution for the complete application using AI. In the case of the smart building, the AI solution is the smart building itself, while the AI service is the digital equipment needed for the smart infrastructure.\\n\\n3.1 First-Order Impacts of an AI Service\\n\\nFirst-order or direct impacts of the AI service are the impacts due to the different life cycle phases of the equipment:\\n\\n- Raw material extraction, which encompasses all the industrial processes involved in the transformation from ore to metals;\\nManufacturing, which includes the processes that create the equipment from the raw material;\\n\\nTransport, which includes all transport processes involved, including product distribution;\\n\\nUse, which includes mostly the energy consumption of equipment while it is being used;\\n\\nand End of life, which refers to the processes to dismantle, recycle, and/or dispose of the equipment.\\n\\nFor simplicity reasons, we will merge the first three items into a single production phase in the rest of the paper. For example, an artificial intelligence (AI) solution in a smart building may need sensors and servers that require resources and energy for their production, operation, and end of life.\\n\\nA second dimension is necessary to assess the impacts, a set of environmental criteria considered. Indeed, each life cycle phase has impacts on different environmental indicators: Greenhouse Gases emissions (usually expressed as Global Warming Potential, GWP), water footprint, human toxicity, or abiotic resource depletion (ADP), for instance. In general, evaluating the environmental impact of a service requires multiple impacts criteria [20]. The International Organization for Standardization (ISO) states that \"the selection of impact categories shall reflect a comprehensive set of environmental issues related to the product system being studied, taking the goal and scope into consideration.\" Additionally, \"the selection of impact categories, indicators, and models...\\n\\n\\nText excerpt from page number 5 and page number 6:\\n(b) Life cycle phases of each device; used by the service\\n\\nFigure 2. Diagram representing the Life Cycle Inventory of an AI service: \\n\\nAbove: An AI for green application corresponds to the inference step that depends on other unit processes requiring various devices. \\n\\nBelow: The use of devices is situated in a broader environment, including the production of resources and impacts. In both schemes, colored boxes represent unit processes, black arrows indicate economic flows (bold for material, dashed for energy), and red arrows signify environmental flows.\\n\\nOther potential equipment not dedicated to the application:\\n\\n- Production and End of life with an allocation of the impacts, with respect to the execution time, for instance.\\n- Part of the use phase corresponding to the dynamic energy consumption, i.e., increase in consumption due to the execution of the program.\\n- Part of the use phase corresponding to the static consumption, with an allocation (for example, if n programs are run simultaneously, 1/n of this consumption) \"since equipment is switched on in part to address the computing needs of the (Machine Learning) model\" [24].\\n\\nThe production phase is generally significant for ICT equipment in terms of global warming potential at least. Yet, when trying to assess this phase for deep learning methods, we face a lack of Life Cycle Assessments (LCAs) for Graphical Processing Units (GPUs), Tensor Processing Units (TPUs), or equivalents. Reference [5] showed that for a CPU-only data center in France, around 40% of the greenhouse gas (GHG) emissions of the equipment were due to the production phase.\\n\\n\\nText excerpt from page number 4:\\nFigure 2 illustrates two aspects of the life cycle of an artificial intelligence (AI) service. The upper section of this figure outlines the various tasks involved in an AI service from a software perspective, such as data acquisition and inference. Each task utilizes one or more devices. The lower section of the figure depicts the life cycle phases of each of these devices from a hardware perspective. The environmental impacts of the AI service originate from these life cycle phases of the devices. It is important to consider all devices involved in the AI tasks.\\n\\nRemark on terminology: In this document, the term \"Use phase\" refers to the use phase of the life cycle of equipment, corresponding to the devices provided for the AI service (indicated as \"Use of device\" in the lower part of Figure 2). The term \"Application phase\" refers to the inference phase of the AI service (highlighted in green in the upper part of Figure 2).\\n\\nRegarding system boundaries, we refer to [1] to consider the equipment for three tiers:\\n- Terminals: In the context of a smart building, this includes user terminals used to develop, train, and use the AI service; terminals in the facility where the AI service is trained, dedicated to IT support; and smart thermostats.\\n- Network: For the smart building scenario, this includes network equipment used for training the AI model in the facility and network equipment in the buildings where the thermostats are used.\\n- Data center/server: For the smart building scenario, this includes servers on which the model is trained and used; training and inference can occur on the same server or different ones.\\n\\nFor each tier, all support equipment and activities should also be considered. For example, the power supply unit and HVAC system of the data center should be taken into account. The life cycle stages to consider are those previously mentioned: production, use, and end of life. Specifically, references [20] and [1] provide classifications of unit processes according to the life cycle stages, which can be applied to AI services, as demonstrated in Table 1.\\n\\nTable 1. Application to AI services of ITU recommendation [20] regarding the evaluation of life cycle stages/unit processes.\\nIf applied to our smart building use case, the unit processes that must be taken into account would be:\\n\\n- For equipment that is dedicated to the application, such as the smart thermostats: Production, Use, and End of Life.\\n- For the servers on which the AI service is trained and used, and their environment (including network devices, storage servers, backup servers, user terminals, HVAC systems, etc.): Production, Use, and End of Life.\\n\\n\\nText excerpt from page number 4:\\nFigure 1. Life Cycle Assessment (LCA) dimensions: The first dimension corresponds to the phases of the life cycle, and the second dimension pertains to the environmental impacts (refer to section 3 for more details on this last dimension). The assessment must be consistent with the goal and scope of the LCA study. Therefore, the costs must at least consider the criteria that the AI solution aims to address in the context of AI for Green. For instance, if the AI solution is applied to reduce energy consumption, the primary expected benefit will likely be in terms of carbon footprint reduction, so the carbon footprint of using the model should be considered. For an application monitoring biodiversity, the most relevant criterion may be natural biotic resources (and not carbon footprint), which include wild animals, plants, etc.\\n\\nFigure 1 summarizes these two dimensions. As previously stated, in the literature, only part of the global warming potential due to the use phase has generally been considered when evaluating AI, which corresponds to the shaded area in the figure.\\n\\n3.2 Life Cycle Assessment Methodology for AI\\n\\nIn this section, we focus on the life cycle assessment of the AI solution and the associated Information and Communication Technology (ICT) equipment. We aim to propose a methodology for applying the general framework of LCA to AI services. For LCA of all other processes, we refer to LCA standards and reference [15], for example. To concretely apply the methodology presented for an AI service, we use the International Telecommunication Union (ITU) recommendation [20] for environmental evaluation of ICT.\\n\\n\\nText excerpt from page number 4:\\n{\"figure title\":\"Life Cycle Assessment Indicators\",\"figure number\":1,\"description\":\"This figure illustrates environmental indicators across different life cycle phases.\",\"components\":[\"ADP\",\"humtox\",\"water\",\"GWP\"],\"relationships\":[{\"indicator\":\"GWP\",\"phase\":\"use\",\"highlighted\":\"true\"}]}\\n{\"indicator\":\"ADP\",\"phase\":\"production\",\"value\":\"not highlighted\"}\\n{\"indicator\":\"ADP\",\"phase\":\"use\",\"value\":\"not highlighted\"}\\n{\"indicator\":\"ADP\",\"phase\":\"end of life\",\"value\":\"not highlighted\"}\\n{\"indicator\":\"humtox\",\"phase\":\"production\",\"value\":\"not highlighted\"}\\n{\"indicator\":\"humtox\",\"phase\":\"use\",\"value\":\"not highlighted\"}\\n{\"indicator\":\"humtox\",\"phase\":\"end of life\",\"value\":\"not highlighted\"}\\n{\"indicator\":\"water\",\"phase\":\"production\",\"value\":\"not highlighted\"}\\n{\"indicator\":\"water\",\"phase\":\"use\",\"value\":\"not highlighted\"}\\n{\"indicator\":\"water\",\"phase\":\"end of life\",\"value\":\"not highlighted\"}\\n{\"indicator\":\"GWP\",\"phase\":\"production\",\"value\":\"not highlighted\"}\\n{\"indicator\":\"GWP\",\"phase\":\"use\",\"value\":\"highlighted\"}\\n{\"indicator\":\"GWP\",\"phase\":\"end of life\",\"value\":\"not highlighted\"}\\n\\nThe diagram presents environmental indicators across various life cycle phases: production, use, and end of life. The indicators include ADP, humtox, water, and GWP. The Global Warming Potential (GWP) is highlighted under the use phase, indicating its significance in that context. Other indicators such as ADP, humtox, and water are not highlighted in any phase, suggesting they may not have relevant data or impact in those phases. This representation emphasizes the importance of considering GWP during the use phase of the life cycle.\\n\\n\\nText excerpt from page number 4:\\n{\"table_title\":\"Application to AI services of ITU recommendation\",\"description\":\"The table outlines the life cycle stages and unit processes for AI services, indicating whether each process is mandatory or recommended.\",\"main_headers\":[\"Life Cycle Stage\",\"Requirement\"]}\\n\\n{\"life_cycle_stage\":\"A - Raw material acquisition\",\"requirement\":\"Mandatory\"}\\n{\"life_cycle_stage\":\"B - Production\",\"requirement\":\"Devices production and assembly\",\"status\":\"Mandatory\"}\\n{\"life_cycle_stage\":\"B - Production\",\"requirement\":\"Manufacturer support activities\",\"status\":\"Recommended\"}\\n{\"life_cycle_stage\":\"B - Production\",\"requirement\":\"Production of support equipment\",\"status\":\"Mandatory\"}\\n{\"life_cycle_stage\":\"B - Production\",\"requirement\":\"ICT-specific site construction\",\"status\":\"Recommended\"}\\n{\"life_cycle_stage\":\"C - Use\",\"requirement\":\"Use of ICT equipment\",\"status\":\"Mandatory\"}\\n{\"life_cycle_stage\":\"C - Use\",\"requirement\":\"Use of support equipment\",\"status\":\"Mandatory\"}\\n{\"life_cycle_stage\":\"C - Use\",\"requirement\":\"Operator support activities\",\"status\":\"Recommended\"}\\n{\"life_cycle_stage\":\"C - Use\",\"requirement\":\"Service provider support activities\",\"status\":\"Recommended\"}\\n{\"life_cycle_stage\":\"D - End of life\",\"requirement\":\"Preparation of ICT goods for reuse\",\"status\":\"Mandatory\"}\\n{\"life_cycle_stage\":\"D - End of life\",\"requirement\":\"Storage / disassembly / dismantling / crushing\",\"status\":\"Mandatory\"}\\n\\nThe following table contains the life cycle stages and unit processes for AI services, indicating whether each process is mandatory or recommended. The stages include raw material acquisition, production, use, and end of life, with specific tasks such as devices production, support activities, and equipment use. Each task is marked as either mandatory or recommended, providing guidance on the necessary requirements for each stage.\\n\\n\\nText excerpt from page number 5:\\n( a ) Different tasks involved in an artificial intelligence (AI) service\\n\\n\\nText excerpt from page number 2 and page number 3:\\nStrubell et al. [29] has received much attention because it revealed a dramatic impact of Natural Language Processing (NLP) algorithms during the training phase: the authors found greenhouse gas (GHG) emissions to be equivalent to 300 flights between New York and San Francisco. Premises of such an approach were already present in [23] for Convolutional Neural Networks (CNN) with less meaningful metrics (energy per image or power with no indications on the global duration).\\n\\nIn [28], the authors observe a more general exponential evolution in deep learning architecture parameters. Therefore, they promote \"Green AI\" to consider energy efficiency at the same level as accuracy in training models and recommend, in particular, to report floating-point operations. Other authors [13] have also reviewed all the methods to estimate energy consumption from computer architecture. They distinguish between different levels of description, such as software/hardware level and instruction/application level, and they consider how those methods can be applied to monitor training and inference phases in machine learning.\\n\\nIn the continuity of [29] and [28], several tools have been proposed to make the impacts of training models more visible. They can be schematically divided into:\\n\\n- Integrated tools, such as Experiment Impact Tracker [17], Carbon Tracker 2 [2], and CodeCarbon 3, which...\\nThe following text discusses various tools and methodologies for assessing the environmental impact of artificial intelligence (AI) systems, particularly focusing on energy consumption and carbon footprint. It mentions Python packages like Experiment Impact Tracker, Carbontracker, and CodeCarbon, which report energy usage and associated carbon emissions. Additionally, online tools such as Green Algorithms and ML CO2 Impact provide estimates based on parameters like training duration, material, and location, though they are noted to be less accurate. The text highlights that AI literature often overlooks the production and end-of-life phases, focusing primarily on direct impacts during the use phase. It cites studies that emphasize the significant emissions from manufacturing, such as those from Apple products, and the need for a comprehensive life cycle assessment approach. Some works aim to optimize AI processes to reduce runtime, energy consumption, and carbon footprint, but they often exclude production and end-of-life phases, limiting their scope. The text also notes that the energy efficiency of machine learning has been a topic of dedicated workshops.\\nWhen designing an AI for Green method, which is a method using AI to reduce energy consumption or to benefit other environmental indicators, the complete impacts of AI should also be considered to build meaningful cost/benefit assessments. Reference [7] proposes a framework for such cost-benefit analysis of AI foundation models to evaluate environmental and societal trade-offs. We discuss this framework in Section 4. Most AI solutions for the environment lack a rigorous evaluation of the cost/benefit balance, and one of our contributions is to advance this issue.\\n\\n4. http://www.green-algorithms.org/  \\n5. https://mlco2.github.io/impact/#compute  \\n6. Workshop on Energy Efficient Machine Learning and Cognitive Computing, https://www.emc2-ai.org/virtual-21  \\n\\n2.3 Life Cycle Assessment  \\nLife Cycle Assessment (LCA) is a widely recognized methodology for environmental impact assessment, with ISO standards (ISO 14040 and ISO 14044) and a specific methodology standard for Information and Communication Technology (ICT) from ETSI/ITU [20]. It quantifies multiple environmental criteria and covers the different life cycle phases of a target system. Reference [15] clearly states that \"to avoid the often seen problem shifting where solutions to a problem create several new and often ignored problems, these decisions must take a systems perspective. They must consider [...] the life cycle of the solution, and they need to consider all the relevant impacts caused by the solution.\" The LCA theoretical approach exposed in [16] describes the system of interest as a collection of building blocks called unit processes, for example, \"Use phase of the server\" on which the model is trained. The set of all unit processes is called the technosphere, as opposed to the ecosphere. Each unit process can be expressed in terms of flows of two kinds:\\nEconomic flows are the directed links between the unit processes, or in other words, exchanges within the technosphere.\\n\\n- Environmental flows are the links from the biosphere to the technosphere or vice versa.\\n\\nThe detailed description of such a system is called the life cycle inventory (LCI), and it can be formulated in terms of linear algebra. The goal of a life cycle assessment is to compute the sum of the environmental flows of the system associated with a functional unit. For example, if one considers a heating system in a smart building, the functional unit could be \"heating 1m² to 20°C for one year.\"\\n\\nOften, the LCI does not correspond exactly to the functional unit. The size of economic flows may not match (e.g., the functional unit may partially use shared servers and sensors), and a process may be multifunctional, producing flows of different types at the same time (e.g., storage capacity and computational power). Both these problems can be solved using allocation methods according to a key. A typical allocation key for network infrastructures would be the volume of data. For a data center, it could be the economic value of storage and computational services when they cannot be physically isolated.\\n\\n\\nText excerpt from page number 1 and page number 2:\\n2022  \\nApr  \\n21  \\n]  \\ncs.AI  \\n[  \\n2110.11822v2  \\n: arXiv  \\nUnraveling the Hidden Environmental Impacts of AI  \\nSolutions for Environment  \\nLife Cycle Assessment of AI Solutions  \\n\\n**Abstract**  \\nIn the past ten years, artificial intelligence (AI) has encountered such dramatic progress that it is now seen as a tool of choice to solve environmental issues, primarily greenhouse gas (GHG) emissions. At the same time, the deep learning community began to realize that training models with more and more parameters requires a lot of energy and, as a consequence, leads to GHG emissions. To our knowledge, questioning the complete net environmental impacts of AI solutions for the environment (AI for Green), and not only GHG, has never been addressed directly. In this article, we propose to study the possible negative impacts of AI for Green. First, we review the different types of AI impacts, then we present the different methodologies used to assess those impacts, and show how to apply life cycle assessment to AI services. Finally, we discuss how to assess the environmental usefulness of a general AI service and point out the limitations of existing work in AI for Green.\\n\\n**Introduction**  \\nIn the past few years, the AI community has begun to address the environmental impacts of deep learning programs: [29] highlighted the impacts of training Natural Language Processing (NLP) models in terms of energy consumption and carbon footprint, [28] proposed the concept of Green AI, and the AI community created several tools to evaluate machine learning energy consumption [2, 17, 21, 22]. These impacts are mainly expressed in terms of energy consumption and associated greenhouse gas (GHG) emissions. Yet, as we will discuss later, this energy consumption represents only a part of the complete environmental impacts of such methods. [11] for example states that \"it is in terms of their indirect effects on the global digital sector that AI systems will have a major impact on the environment.\" In the same spirit, [33] warns that \"optimizing actions for a restricted set of parameters (profit, job security, etc.) without consideration of these wider impacts can lead to consequences for...\\nothers, including one\\'s future self as well as future generations.\"\\n\\nEvaluating the impacts of an artificial intelligence (AI) service is not fundamentally different from evaluating another digital service. However, AI presents specific characteristics that must be taken into account because they increase its environmental impacts.\\n\\nFirst, AI, and in particular deep learning methods, usually require large quantities of data. These data must be acquired, transferred, stored, and processed. All these steps require equipment and energy, which have environmental impacts. For example, in the case of a surveillance satellite, the data will probably be in large quantities, but the number of acquisition devices may be limited. In contrast, in the case of a smart building infrastructure, the data may be in smaller quantities, but many devices will be required.\\n\\nTraining deep neural models also takes a lot of computation time and resources, partly because the model itself learns a comprehensive representation that enables it to better analyze the data. Whereas with other models, a human will provide part of this information, often in the form of a handcrafted solution. The computation cost can be even higher if the model does continuous learning.\\n\\nAt the same time, AI\\'s popularity is increasing, and AI is often presented as a solution to environmental problems with AI for Green proposals [12, 26, 32]. The negative environmental impacts can be briefly evoked, particularly rebound effects [26?], where unitary efficiency gains can lead to a global increase in greenhouse gas (GHG) emissions. However, no quantification of all AI\\'s environmental costs is proposed to close the loop between AI for Green and Green AI. That is why it is even more important to be able to assess the actual impacts, taking into account both positive and negative effects.\\nIncidentally, those works often use the term \"artificial intelligence\" (AI) to actually refer to deep learning methods, even though AI has a much wider scope with at least two major historical trends [9]. In this paper, we will also focus on deep learning methods, which pose specific environmental issues, and as we have seen, are often presented as possible solutions to environmental problems. We describe these impacts and discuss how to take them into account.\\n\\nOur contributions are the following:\\n\\n• We review the existing work to assess the environmental impacts of AI and show their limitations (Sections 2.1 and 2.2).\\n\\n• We present life cycle assessment (Section 2.3) and examine how it can comprehensively evaluate the direct environmental impacts of an AI service (Section 3).\\n\\n• We discuss how to assess the environmental value of an AI service designed for environmental purposes (Section 4).\\n\\n• We argue that although improving the state of the art, the proposed methodology can only show the technical potential of a service, which may not fully realize in a real-life context (Section 5).\\n\\n2 Related Work\\n\\nThis section reviews existing tools for evaluating environmental impacts of AI as well as green applications of AI. It ends with an introduction to life cycle assessment, a well-founded methodology for environmental impact assessment but still not used for AI services.\\n\\n2.1 Carbon Footprint of AI\\n\\n\\nText excerpt from page number 1:\\n{\"table_title\":\"Missing\",\"table_number\":\"Missing\",\"description\":\"List of authors and their affiliations\",\"main_headers\":[\"Name\",\"Affiliation\",\"Location\"]}\\n{\"name\":\"Anne-Laure Ligozat\",\"affiliation\":\"Univ. Paris-Saclay, LIMSI, CNRS, ENSIIE\",\"location\":\"Orsay, France\"}\\n{\"name\":\"Julien Lefèvre\",\"affiliation\":\"Univ. Aix-Marseille, CNRS, Centrale Marseille\",\"location\":\"Marseille, France\"}\\n{\"name\":\"Aurélie Bugeau\",\"affiliation\":\"Univ. Bordeaux, Bordeaux INP, CNRS, Laboratoire LaBRI\",\"location\":\"Talence, France\"}\\n{\"name\":\"Jacques Combaz\",\"affiliation\":\"Universite Grenoble Alpes, VERIMAG\",\"location\":\"Grenoble, France\"}\\n\\nThe first author is Anne-Laure Ligozat from Univ. Paris-Saclay, located in Orsay, France. The second author is Julien Lefèvre from Univ. Aix-Marseille, located in Marseille, France. The third author is Aurélie Bugeau from Univ. Bordeaux, located in Talence, France. The fourth author is Jacques Combaz from Universite Grenoble Alpes, located in Grenoble, France.\\n\\n\\nThe following text excerpts are from the same section of a document named \\'2110.11822v2.pdf\\':\\n\\nText excerpt from page number 8 and page number 9:\\nFigure 4. Sankey diagram illustrating parts of Rolnick\\'s paper references in terms of environmental evaluation (created with the Sankey Diagram Generator by Dénes Csala, based on the Sankey plugin for D3 by Mike Bostock; available at https://sankey.csaladen.es; 2014). It can be noted that other papers, which include an evaluation of part of these impacts, can be found in the literature. For example, reference [8] presents intelligent control systems that consider expected occupancy to adapt the thermostat and save energy. They do not account for learning the occupancy model but do consider the life cycle assessment (LCA) of smart thermostats, showing that the energy required for these devices across their entire life cycle is almost always lower than the energy saved.\\n\\nDiscussion\\n\\nIn this paper, we have analyzed the environmental impacts of AI solutions, particularly in the case of AI for Green applications, and proposed a framework to evaluate them more comprehensively. The proposed methodology compares, through life cycle assessment, the impact of a reference solution with the AI one (1) for the appropriate types of environmental impacts. The analysis of literature on AI solutions has highlighted the following issues/problems.\\n\\n5.1 Current environmental evaluation of AI services is underestimated\\n\\nWe have shown that AI for Green papers only consider a small part of the direct environmental impacts. Several reasons can explain this underestimation. The narratives about dematerialization, which would correspond to a dramatic decrease in environmental impacts, permeate AI as a part of Information and Communication Technology (ICT) [6]. However, these narratives have proven to be false until now. Attention to AI\\'s greenhouse gas (GHG) emissions has focused on electricity consumption (energy flows). At the moment, material flows receive less attention in AI. However, they are beginning to be considered [14?].\\n\\n5.2 AI research should use Life Cycle Assessment to assess the usefulness of an AI service\\nLife cycle assessment (LCA) is a robust methodology used to evaluate not only the global warming potential but also other direct environmental impacts. LCA considers all steps from production to use and end-of-life. However, it faces several well-known limitations due to the complexity of processes involved in material production. Obtaining all necessary information to assign reliable values to each part of the life cycle inventory is challenging. For example, there is very little information on the manufacturing impacts of Graphics Processing Units (GPUs) from either manufacturers or in LCA databases. To address this issue, the AI community could encourage companies to open part of their data, similar to the movement towards open science, while also considering legal issues.\\n\\n5.3 AI for Green gains are only potential  \\nEven when a properly conducted LCA concludes that an AI solution is environmentally beneficial, such a result should be considered with caution. The environmental benefits computed by the LCA-based methodology proposed in this paper represent a technical and simplistic view of environmental problems. It assumes that AI will enhance or replace existing applications, all other factors remaining constant. While the ambition to solve societal problems using AI is commendable, it should be accompanied by socio-technical concerns and an evaluation of possible third-order effects. For example, autonomous vehicles are often associated with potential efficiency gains, such as facilitating car sharing or allowing platooning, and corresponding environmental benefits. However, autonomy could also significantly transform mobility in a non-ecological way.\\n\\nAI - Artificial Intelligence  \\nCNN - Convolutional Neural Network  \\nCPU - Central Processing Unit  \\nDL - Deep Learning  \\nGHG - Greenhouse Gas  \\nGPU - Graphics Processing Unit  \\nICT - Information and Communications Technology  \\nHVAC - Heating, Ventilation, and Air Conditioning  \\nLCA - Life Cycle Assessment or Analysis  \\nLCI - Life Cycle Inventory  \\nML - Machine Learning  \\nNLP - Natural Language Processing  \\n\\n5.4 AI services and large deployment\\nEvaluating third-order effects is even more critical when large-scale deployment of the proposed solution(s) is projected, for example, to maximize absolute gains. This scenario requires special attention even in Life Cycle Assessment (LCA), since large-scale deployment may induce societal reorganizations for producing and operating the solution(s). For example, the generalization of Artificial Intelligence (AI) may lead to a substantial increase in demand for specific materials, such as lithium or cobalt, or energy. This increase may have non-linear environmental consequences, such as opening new and less performing mines, increasing the use of fossil fuel-based power plants, etc. Hence, in this case, the attributional LCA framework we suggest using in this paper needs to be replaced by the much more complex consequential one [15].\\n\\nAuthors\\' Contribution  \\n- Conceptualization: all authors  \\n- Methodology: all authors  \\n- Validation: all authors  \\n- Formal analysis: all authors  \\n- Investigation: J.L. and A.-L. L.  \\n- Data curation: J.L. and A.-L. L.  \\n- Writing—original draft preparation: all authors  \\n- Writing—review and editing: all authors  \\n- Visualization: A.B. and A.-L. L.  \\n- Supervision: A.-L. L.  \\n- Project administration: A.-L. L.  \\n\\nAll authors have read and agreed to the published version of the manuscript.\\n\\nAcknowledgments  \\nThis work was partly supported by the CNRS EcoInfo group (https://ecoinfo.cnrs.fr/).\\n\\nAbbreviations  \\nThe following abbreviations are used in this manuscript:  \\n- TPU: Tensor Processing Unit\\n\\nReferences\\n\\n\\nText excerpt from page number 7:\\nE ( M ) the energy cost of the model\\n\\n⚫ O ( M ) all other impacts including chip production, waste, risks for biodiversity, and third-order impacts (which are not discussed here).\\n\\nRegarding the well-established framework of Life Cycle Assessment (LCA), this approach suffers from several weaknesses. First, in the equation, all the values are expressed in dollars. This formally allows for the addition of several kinds of impacts but with an arbitrary consideration of the diversity of environmental issues. By definition, LCA considers multiple criteria for the impacts, previously described at the beginning of Section 3 (such as greenhouse gas emissions, water footprint, etc.). LCA may aggregate several impacts but with specific weights not necessarily dependent on an economic value. As noted in reference [15], \"there is no scientific basis on which to reduce the results of an LCA to a single result or score because of the underlying ethical value-choices.\"\\n\\nBesides, if one considers, for instance, the case of an AI service dedicated to biodiversity (see, for instance, Section 8.1 in reference [26]), one would expect to precisely quantify the positive impact of this service on biodiversity (schematically, how many species can be saved?) balanced by the negative ones (producing chips for GPUs has an impact on biodiversity through several sources of pollution [31]). Adopting Equation (2) will mix several impacts together and may dilute the value of interest (e.g., biodiversity), which could be burdened by negative impacts regarding energy to train the models, for instance.\\nLast, even if the equation is not wrong per se, the expression in terms of benefit/costs is questionable, and practical means for its computation are missing in reference [7]. We thus believe that Equation (1) should be used. Terms of Equation (2) can be related to the methodology proposed in our paper as follows:\\n\\n\\\\[ V(M2) = S(M2 | M₁) - E(M2) - O(M2) - A(M2 | M₁) - LCAAI(M2) \\\\]\\n\\nwhere \\\\( A(M2 | M₁) \\\\) and \\\\( LCAAI(M2) \\\\) are defined in Equation (1). The negative impacts of an AI solution \\\\( M2 \\\\) compared to the reference solution \\\\( M₁ \\\\) are not always restricted to its AI part (i.e., to \\\\( E(M2) \\\\) and \\\\( O(M2) \\\\)). For example, compared to a standard vehicle, the negative impacts of an autonomous vehicle are not only due to the life cycle of (additional) ICT equipment, but also to additional aerodynamic drag due to the presence of LIDAR on the roof [30]. Hence, the nature of the impacts in \\\\( S(M2 | M₁) \\\\) (positive or negative) cannot be stated a priori and depends on complete LCA results for both applications \\\\( M2 \\\\) and \\\\( M₁ \\\\). It may also depend on the target environmental criteria.\\n\\n4.2 Case Studies\\nIn order to review the kind of evaluation that is usually made in the AI for Green literature, we analyzed the references for several domains of the study identified in reference [26], which highlights potential applications of machine learning for climate change adaptation or mitigation. We mostly chose domains that had been flagged as having a High Leverage and noted for each paper cited in the corresponding section the kind of environmental evaluation, with the following categories:\\n\\na. No mention of the environmental gain.\\n\\nb. General mention of the environmental gain.\\n\\nc. A few words about the environmental gain but no quantitative evaluation or only indirect estimation.\\n\\nd. Evaluation of the energy gain without taking the AI service into account.\\n\\ne. Evaluation of the energy gain taking the use phase of the AI service into account.\\n\\nf. Comprehensive evaluation of the environmental gain (comparison of Life Cycle Assessments, LCAs).\\n\\nThe results of the review are shown in Figure 4. The central node is \"Rolnick et al. citations.\" On its left are the domains of the citations. For example, the Smart building section contained 15 relevant citations. On its right, the first flows show the partition into general machine learning applications (ML), deep learning applications (DL), and other methods (other). For example, 20 papers corresponded to deep learning applications. The last flows on the right show the kinds of environmental evaluation. We can note that about half of the papers do not include any environmental evaluation, although the focus is on applications to tackle climate change. Many papers also give a distant proxy for evaluation, such as detailing the possible impacts without quantification, or indicating the execution time of the program. A few citations evaluate the environmental gain, mostly in terms of energy gain, but none of the papers considered took into account the AI service impacts.\\n\\nThis review was documented in a CSV file, which is given as supplementary material to the paper.\\n\\n\\nText excerpt from page number 9:\\n[1] ADEME (2021). General principles for the environmental labeling of consumer products, methodological standard for the environmental assessment of digital services. Technical report, ADEME.\\n\\n[2] Anthony, L. F. W., Kanding, B., and Selvan, R. (2020). Carbontracker: Tracking and Predicting the Carbon Footprint of Training Deep Learning Models. arXiv:2007.03051.\\n\\n[3] Baldé, C. P., Forti, V., Gray, V., Kuehr, R., and Stegmann, P. (2017). The global e-waste monitor 2017: Quantities, flows, and resources. United Nations University, International Telecommunication Union, and International Solid Waste Association.\\n\\n[4] Berkhout, P. H., Muskens, J. C., and Velthuijsen, J. W. (2000). Defining the rebound effect. Energy Policy, 28(6): 425-432.\\n\\n[5] Berthoud, F., Bzeznik, B., Gibelin, N., Laurens, M., Bonamy, C., Morel, M., and Schwindenhammer, X. (2020). Estimation of the carbon footprint of one hour of core computing. Research report, UGA - Université Grenoble Alpes CNRS INP Grenoble; INRIA.\\n[6] Bol, D., Pirson, T., and Dekimpe, R. (2021). \"Moore\\'s Law and ICT Innovation in the Anthropocene.\" In Proceedings of the IEEE Design and Test in Europe Conference, Grenoble, France, pages 1-5.\\n\\n[7] Bommasani, R., Hudson, D. A., Adeli, E., Altman, R., Arora, S., von Arx, S., Bernstein, M. S., Bohg, J., Bosselut, A., Brunskill, E., Brynjolfsson, E., Buch, S., Card, D., Castellon, R., Chatterji, N., Chen, A., Creel, K., Davis, J. Q., Demszky, D., Donahue, C., Doumbouya, M., Durmus, E., Ermon, S., Etchemendy, J., Ethayarajh, K., Fei-Fei, L., Finn, C., Gale, T., Gillespie, L., Goel, K., Goodman, N., Grossman, S., Guha, N., Hashimoto, T., Henderson, P., Hewitt, J., Ho, D. E., Hong, J., Hsu, K., Huang, J., Icard, T., Jain, S., Jurafsky, D., Kalluri, P., Karamcheti, S., Keeling, G., Khani, F., Khattab, O., Koh, P. W., Krass, M., Krishna, R., Kuditipudi, R., Kumar, A., Ladhak, F., Lee, M., Lee, T., Leskovec, J., Levent, I., Li, X. L., Li, X., Ma, T., Malik, A., Manning, C. D., Mirchandani, S., Mitchell, E., Munyikwa, Z., Nair, S., Narayan, A., Narayanan, D., Newman, B., Nie, A., Niebles, J. C., Nilforoshan, H., Nyarko, J., Ogut, G., Orr, L., Papadimitriou, I., Park, J. S., Piech, C., Portelance, E., Potts, C., Raghunathan, A., Reich, R., Ren, H., Rong, F., Roohani, Y., Ruiz, C., Ryan, J., Ré, C., Sadigh, D., Sagawa, S., Santhanam, K., Shih, A., Srinivasan, K., Tamkin, A., Taori, R., Thomas, A. W., Tramèr, F., Wang, R. E., Wang, W., Wu, B., Wu, J., Wu, Y., Xie, S. M., Yasunaga, M., You, J., Zaharia, M., Zhang, M., Zhang, T., Zhang, X.\\n\\nThe text above lists references from a document discussing the environmental impacts of artificial intelligence (AI) solutions. Reference [6] is a paper by Bol, Pirson, and Dekimpe, presented at the IEEE Design and Test in Europe Conference in Grenoble, France, which explores the relationship between Moore\\'s Law and ICT innovation in the context of the Anthropocene. Reference [7] is a comprehensive list of authors who contributed to a study on AI, highlighting the extensive collaboration involved in AI research. These references suggest the document\\'s focus on the intersection of technology, innovation, and environmental considerations, emphasizing the need for a holistic evaluation of AI\\'s environmental impacts. The document likely critiques existing methodologies and proposes a more comprehensive approach to assessing AI\\'s environmental effects, considering both direct and indirect impacts.\\n\\n\\nText excerpt from page number 10:\\n[20] ITU-T (2014). Methodology for environmental life cycle assessments of information and communication technology goods, networks, and services. Technical report, ITU-T.\\n\\n[21] Lacoste, Alexandre, Luccioni, Alexandra, Schmidt, Victor, and Dandres, Thomas (2019). Quantifying the Carbon Emissions of Machine Learning. arXiv:1910.09700.\\n\\n[22] Lannelongue, Laurent, Grealey, James, and Inouye, Michael (2020). Green Algorithms: Quantifying the carbon emissions of computation.\\n\\n[23] Li, Dong, Chen, Xue, Becchi, Michela, and Zong, Ziliang (2016). Evaluating the Energy Efficiency of Deep Convolutional Neural Networks on CPUs and GPUs. In IEEE International Conferences on Big Data and Cloud Computing (BDCloud), Social Computing and Networking (SocialCom), Sustainable Computing and Communications (SustainCom) (BDCloud-SocialCom-SustainCom).\\n\\n[24] Ligozat, Anne-Laure and Luccioni, Alexandra (2021). A Practical Guide to Quantifying Carbon Emissions for Machine Learning Researchers and Practitioners. Technical report, BigScience project, LISN and MILA.\\n\\n[25] Patterson, David, Gonzalez, Joseph, Le, Quoc, Liang, Chen, Munguia, Luis-Manuel, Rothchild, Daniel, So, David, Texier, Mathieu, and Dean, Jeffrey (2021). Carbon emissions and large neural network training. arXiv:2104.10350.\\n\\n[26] Rolnick, David, Donti, Priya L., Kaack, Lynn H., Kochanski, Kelly, Lacoste, Alexandre, Sankaran, Kris, Ross, Andrew S., Milojevic-Dupont, Nikola, Jaques, Natasha, Waldman-Brown, Anna, Luccioni, Alexandra, Maharaj, Tegan, Sherwin, Evan D., Mukkavilli, Sandeep K., Kording, Konrad P., Gomes, Carla, Ng, Andrew Y., Hassabis, Demis, Platt, John C., Creutzig, Felix, Chayes, Jennifer, and Bengio, Yoshua (2019). Tackling Climate Change with Machine Learning. arXiv:1906.05433.\\n[27] Schneider, F., Hinterberger, F., Mesicek, R. H., and Luks, F. (2001). Eco-info-society: Strategies for an ecological information society.\\n\\n[28] Schwartz, R., Dodge, J., Smith, N. A., and Etzioni, O. (2020). Green AI. Communications of the ACM, 63(12): 54-63.\\n\\n[29] Strubell, E., Ganesh, A., and McCallum, A. (2019). Energy and Policy Considerations for Deep Learning in Natural Language Processing. arXiv: 1906.02243.\\n\\n[30] Taiebat, M., Brown, A. L., Safford, H. R., Qu, S., and Xu, M. (2018). A review on energy, environmental, and sustainability implications of connected and automated vehicles. Environmental Science & Technology, 52(20): 11449-11465. PMID: 30192527.\\n\\n[31] Villard, A., Lelah, A., and Brissaud, D. (2015). Drawing a chip environmental profile: Environmental indicators for the semiconductor industry. Journal of Cleaner Production, 86: 98-109.\\n\\n[32] Vinuesa, R., Azizpour, H., Leite, I., Balaam, M., Dignum, V., Domisch, S., Felländer, A., Langhans, S. D., Tegmark, M., and Fuso Nerini, F. (2020). The role of artificial intelligence in achieving the Sustainable Development Goals. Nature Communications, 11(1): 233.\\n\\n[33] Walsh, T., Evatt, A., and de Witt, C. S. (2020). Artificial intelligence & climate change: Supplementary impact report. Technical report, University of Oxford.\\n\\n\\nText excerpt from page number 8:\\n{\"figure_title\":\"Sankey Diagram of Citation Distribution\",\"figure_number\":4,\"description\":\"This diagram illustrates the distribution of citations across various environmental evaluation topics.\",\"components\":[\"Elec Vehicles\",\"Smart buildings\",\"Low carbon\",\"Modeling demand\",\"Freight\",\"ML\",\"DL\",\"none\"],\"relationships\":[{\"source\":\"Elec Vehicles\",\"target\":\"Rolnick and al citations\",\"count\":17},{\"source\":\"Smart buildings\",\"target\":\"Rolnick and al citations\",\"count\":15},{\"source\":\"Low carbon\",\"target\":\"Rolnick and al citations\",\"count\":14},{\"source\":\"Modeling demand\",\"target\":\"Rolnick and al citations\",\"count\":7},{\"source\":\"Freight\",\"target\":\"Rolnick and al citations\",\"count\":4},{\"source\":\"Rolnick and al citations\",\"target\":\"ML\",\"count\":29},{\"source\":\"Rolnick and al citations\",\"target\":\"DL\",\"count\":20},{\"source\":\"Rolnick and al citations\",\"target\":\"none\",\"count\":8},{\"source\":\"ML\",\"target\":\"a\",\"count\":24},{\"source\":\"ML\",\"target\":\"b\",\"count\":9},{\"source\":\"DL\",\"target\":\"c\",\"count\":18},{\"source\":\"none\",\"target\":\"d\",\"count\":6}]}\\n{\"element\":\"Elec Vehicles\",\"connected_to\":\"Rolnick and al citations\",\"count\":17}\\n{\"element\":\"Smart buildings\",\"connected_to\":\"Rolnick and al citations\",\"count\":15}\\n{\"element\":\"Low carbon\",\"connected_to\":\"Rolnick and al citations\",\"count\":14}\\n{\"element\":\"Modeling demand\",\"connected_to\":\"Rolnick and al citations\",\"count\":7}\\n{\"element\":\"Freight\",\"connected_to\":\"Rolnick and al citations\",\"count\":4}\\n{\"element\":\"Rolnick and al citations\",\"connected_to\":\"ML\",\"count\":29}\\n{\"element\":\"Rolnick and al citations\",\"connected_to\":\"DL\",\"count\":20}\\n{\"element\":\"Rolnick and al citations\",\"connected_to\":\"none\",\"count\":8}\\n{\"element\":\"ML\",\"connected_to\":\"a\",\"count\":24}\\n{\"element\":\"ML\",\"connected_to\":\"b\",\"count\":9}\\n{\"element\":\"DL\",\"connected_to\":\"c\",\"count\":18}\\n{\"element\":\"none\",\"connected_to\":\"d\",\"count\":6}\\n\\nThe Sankey diagram represents the distribution of citations from various environmental evaluation topics to the central node \"Rolnick and al citations.\" The categories include \"Elec Vehicles\" with 17 citations, \"Smart buildings\" with 15, \"Low carbon\" with 14, \"Modeling demand\" with 7, and \"Freight\" with 4 citations. These citations flow into the central node, which then distributes them to \"ML\" (Machine Learning) with 29 citations, \"DL\" (Deep Learning) with 20, and \"none\" with 8 citations. Further, \"ML\" connects to categories \"a\" with 24 citations and \"b\" with 9 citations, while \"DL\" connects to \"c\" with 18 citations, and \"none\" connects to \"d\" with 6 citations. This diagram highlights the flow and distribution of research citations across different AI and environmental topics.\\n\\n\\nText excerpt from page number 9 and page number 10:\\nZhang, Y., Zheng, L., Zhou, K., and Liang, P. (2021). On the Opportunities and Risks of Foundation Models. arXiv:2108.07258.\\n\\n[8] Bracquené, E., De Bock, Y., and Duflou, J. (2020). Sustainability impact assessment of an intelligent control system for residential heating. Procedia CIRP, 90: 232-237. Presented at the CIRP Life Cycle Engineering (LCE) Conference.\\n\\n[9] Cardon, D., Cointet, J.-P., Mazières, A., and Libbrecht, E. (2018). Neurons spike back. Reseaux, 211(5): 173-220.\\n\\n[10] Coroamă, V. C. and Pargman, D. (2020). Skill rebound: On an unintended effect of digitalization. In Proceedings of the 7th International...\\nConference on ICT for Sustainability, ICT4S2020, pages 213-219, New York, NY, USA. Published by the Association for Computing Machinery.\\n\\n[11] Dilhac, Marie-Aude, Abrassart, C., Voarino, N., et al. (2018). Montréal Declaration for a Responsible Development of Artificial Intelligence - 2018 Report. Technical report by IA Responsable.\\n\\n[12] Gailhofer, Peter, Herold, A., Schemmel, J. P., Scherf, C. U., Köhler, A. R., and Braungardt, S. (2021). The Role of Artificial Intelligence in the European Green Deal. Technical report prepared for the Special Committee on Artificial Intelligence in a Digital Age (AIDA), Policy Department for Economic, Scientific and Quality of Life Policies, European Parliament.\\n\\n[13] García-Martín, E., Rodrigues, C. F., Riley, G., and Grahn, H. (2019). Estimation of Energy Consumption in Machine Learning. Journal of Parallel and Distributed Computing, Volume 134, pages 75-88.\\n\\n[14] Gupta, Udit, Kim, Young Geun, Lee, S., Tse, J., Lee, H.-H. S., Wei, G.-Y., Brooks, D., and Wu, C.-J. (2020). Chasing Carbon: The Elusive Environmental Footprint of Computing. Available on arXiv: 2011.02839.\\n[15] Hauschild, M. Z., Rosenbaum, R. K., and Olsen, S. I. (2018). Life Cycle Assessment, Volume 2018. Springer.\\n\\n[16] Heijungs, R. and Suh, S. (2002). The Computational Structure of Life Cycle Assessment, Volume 11. Springer Science & Business Media.\\n\\n[17] Henderson, P., Hu, J., Romoff, J., Brunskill, E., Jurafsky, D., and Pineau, J. (2020). Towards the Systematic Reporting of the Energy and Carbon Footprints of Machine Learning.\\n\\n[18] Hilty, L. M. and Hercheui, M. D. (2010). ICT and Sustainable Development. In What Kind of Information Society? Governance, Virtuality, Surveillance, Sustainability, Resilience, pages 227-235. Springer.\\n\\n[19] Horner, N. C., Shehabi, A., and Azevedo, I. L. (2016). Known Unknowns: Indirect Energy Effects of Information and Communication Technology. Environmental Research Letters, 11(10): 103001.\\n\\n\\nThe following text excerpt is from a section of a document named \\'2110.11822v2.pdf\\':\\n\\nText excerpt from page number 6 and page number 7:\\nThe use phase of AI solutions is primarily influenced by energy consumption, making the impacts of this phase highly dependent on the efficiency of the server or facility and the carbon intensity of the energy sources utilized. Assessing the end-of-life phase in Information and Communication Technology (ICT) is challenging due to insufficient data, as approximately 80% of electronic and electrical equipment is not formally collected globally. This section focuses on assessing the usefulness of an AI for Green service by adapting the general framework of life cycle assessment to AI solutions. The evaluation considers two scenarios: a reference application M₁, which represents the application without AI capabilities, such as a standard building, and an AI-enhanced application M₂, which includes AI services intended to positively impact the environment, like a smart building. Theoretical aspects of this assessment are further explored in the following section.\\nWhen proposing an AI for Green method, it is crucial to ensure that the overall environmental impact is positive: the positive gain induced by using the AI solution should outweigh the negative impacts associated with the solution. This requires assessing first-order, second-order, and third-order impacts of AI, as illustrated in Figure 3. As detailed in the previous section, first-order impacts arise from the life cycle phases of all the equipment necessary to develop and deploy the AI service. \\n\\nSecond-order impacts correspond to the impacts due to the application of AI. AI can optimize or substitute existing systems; for example, energy consumption in a building can be optimized using occupancy or behavior detection, energy profiling, etc. Third-order impacts include all changes in technology or society due to the introduction of AI solutions, possibly encompassing effects of very different scales, from individual behavioral responses to systemic and societal transformations, and from short-term to long-term effects. Rebound effects fall into this category: an increase in efficiency does not necessarily translate into a reduction of impacts of the same magnitude, and it can even lead to an increase in these impacts. Rebound effects occur because potential savings (in terms of money, time, resources, etc.) are transformed into more consumption. For example, due to economic savings, smart building users may decide to increase heating temperature for better comfort or to buy more flight tickets after an increase in energy efficiency.\\n\\nThird-order impacts are beyond the scope of the methodology proposed here and are briefly discussed in Section 5. According to the referenced source, first and second-order impacts of the AI service should be estimated based on life cycle assessment (LCA), with the difference between the two being the scope: for first-order impacts, the scope is restricted to the equipment involved in the target AI service (for example, the AI involved in a smart building), while second-order impacts consider the whole solution (the smart building itself). Including second-order impacts requires extending the scope to the whole application AI is supposed to enhance. More specifically, the net environmental impacts considering both first and second-order effects are obtained by computing:\\n\\n\\\\[ A ( M2 | M₁ ) = LCA ( M2 ) - LCA ( M₁ ) \\\\in \\\\mathbb{R}^d \\\\]\\n\\nwhere:\\n- \\\\( M₁ \\\\) is the reference application without using the AI service.\\nM2, the application enhanced by Artificial Intelligence (AI),\\n\\n- LCA (Life Cycle Assessment) (x): A quantification of different types of environmental impacts (e.g., greenhouse gas (GHG) emissions, water footprint, etc.). The LCA methodology is described in Section 3.2. Note that LCA (M2) includes the impacts of the AI service itself, i.e., LCA_AI (M2). A previous work [7] also provided a simplified scheme for assessing the cost-benefit of deploying a foundation model, which includes social benefits and costs but does not explicitly address the direct environmental costs of using this model. We propose to relate our methodology (Equation (1)) to their proposal. By adopting their equation but focusing solely on the environmental impacts, the overall value of a model can be assessed with:\\n\\nV(M) = S(M) - E(M) - O(M) (Equation 2)\\n\\n- V(M): The value of using the model, i.e., the environmental gain induced by its use in the practical application considered.\\n\\n- S(M): The environmental benefit, which can be interpreted as the difference between the initial impact of the application and its final impact (not taking into account the AI solution, i.e., the Learning and Inference task in the top part of Figure 2).'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exploring the formatted context to provide to the language model\n",
    "response.search.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pqwJ_CTViPk0"
   },
   "source": [
    "# RAG\n",
    "Now that we understand EyeLevel's X-Ray and GroundX more thoroughly, we can explore their application. In this example we'll be using [search.content](https://documentation.eyelevel.ai/reference/Search/Search_content) to search for relevent information, and pass GroundX's formatted aggregation to the language model.\n",
    "\n",
    "GroundX's formatted aggregation is designed to put the most important things at the beginning. To use it for different sized language models, you can simply keep the first `n` charecters in the sequence. We've found that `n = 3*token_limit` typically works well, but more sophisticated token counting techniques can also be employed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oqZCrUiSk6vd",
    "outputId": "76387035-e5b5-4cee-ddec-6e69ffc93552"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response:\n",
      "The major parts of the AI lifecycle, as mentioned in the document, include:\n",
      "\n",
      "1. Raw material extraction: This includes all the industrial processes involved in the transformation from ore to metals.\n",
      "2. Manufacturing: This encompasses the processes that create the equipment from the raw material.\n",
      "3. Transport: This includes all transport processes involved, including product distribution.\n",
      "4. Use: This primarily involves the energy consumption of the equipment while it is being used.\n",
      "5. End of life: This refers to the processes to dismantle, recycle, and/or dispose of the equipment.\n",
      "\n",
      "These phases are later simplified in the document to a single production phase, which combines raw material extraction, manufacturing, and transport.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "\"\"\"Defining RAG\n",
    "using GroundX Search to retrive information, constructing an\n",
    "augmented prompt based on GX's recommended textual representation,\n",
    "and using OpenAI to generate a response.\n",
    "\"\"\"\n",
    "\n",
    "# ==== Retreival ====\n",
    "def gx_search(query):\n",
    "    response = client.search.content(\n",
    "        id=bucket_id,\n",
    "        query=query\n",
    "    )\n",
    "    return response.search.text\n",
    "\n",
    "# ==== Augmentation ====\n",
    "def gx_retrieve_and_augment(query):\n",
    "\n",
    "    #getting context\n",
    "    context = gx_search(query)\n",
    "\n",
    "    if len(context) > 4000 * 3:\n",
    "        context = context[:4000*3]\n",
    "\n",
    "    #defining a high level prompt so the LLM knows what to do\n",
    "    system_prompt = 'you are a helpful AI agent tasked with helping users extract information from the context below'\n",
    "\n",
    "    #based on OpenAI's new formatting\n",
    "    augmented_prompt = [{\n",
    "        \"role\": \"system\",\n",
    "        \"content\": system_prompt+'\\n\\n===\\n'+context+'\\n==='},\n",
    "         {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": query\n",
    "         }]\n",
    "\n",
    "    return augmented_prompt\n",
    "\n",
    "# ==== Generation ====\n",
    "def gxrag(query):\n",
    "\n",
    "    #retrieving and augmenting\n",
    "    augmented_prompt = gx_retrieve_and_augment(query)\n",
    "\n",
    "    #Generating\n",
    "    client = OpenAI()\n",
    "    return client.chat.completions.create(model=\"gpt-4\",messages=augmented_prompt).choices[0].message.content\n",
    "\n",
    "res = gxrag('What are the major parts of the AI lifecycle?')\n",
    "print('response:')\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qPhdbQ6-l5hi"
   },
   "source": [
    "# Image Reporting\n",
    "Sometimes you don't only want a language model to answer the question for you. While RAG is useful, sometimes text simply isn't the appropriate response. In this example we'll use the same search approach as before, but provide a rich report of pages and figures, allong with generation, which might answer the question. This will allow a human to quickly evaluate the truthfullness of the generation, and come to their own conclusions as necessary.\n",
    "\n",
    "Because X-Ray is multimodal by nature, the resulting semantic objects contain a variety of visual information which can be referenced. GroundX is useful in searching, but it's important to note that the GroundX ranking is designed for textual rather than visual search. As a result the most relevent diagram may not be the first search result from GroundX.\n",
    "\n",
    "This can be easily aleviated by using a CLIP style model as a re-ranker, allowing for the most visually relevent information to be prioritized. It's unlikely that a small clip style model can understand image content, but it can likely seperate high level correct and incorrect types of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273,
     "referenced_widgets": [
      "2de01ad7eef2491dbdb38fac20586247",
      "ef7f99718dc040eb9632e7a399c91aaa",
      "4ea89bf3cc4c43f8874efb789942411a",
      "82f17ba5f8b646ee879566628df86101",
      "dd5deaa200eb462e957bd3bfe18cd4c8",
      "8bba39017c3e4d678cb7ab41102decde",
      "d8b3ae97e6b5436d9b91db60350cc817",
      "b2461ed08acb4a1687be8f12e7e9f6b6",
      "8068671318464f1ea2670fad0ebaebda",
      "b143e1f08fb74385be4994ba372f64ec",
      "c6fad28c4d9241f9b200165ce6de3641",
      "529a3de1631342d2a2ce854b0ea7937b",
      "0453cd0618de4e55948be081b3caa50f",
      "b9ce3f1bafd54c0fa6d625560d3e365d",
      "e64bfa90d3294e31ad2ab09fe2d71164",
      "2251e6ecb6594da7a40e815281c371b8",
      "13fbc9ac68264948904524f8838e2809",
      "307091e60cbd4347a2c5ca282d62b5e4",
      "11c1e0d6f6fe4821a0de19c33aae87f7",
      "bc63f2535ffd4b7cae744c998b557fb2",
      "f3ef2611d917486b89f77574e5670941",
      "95339a33915b480a9a8caf8f9fc05a7e",
      "da071879235a42bd8651bec7fa6b607b",
      "72f717b1bf0f40978a44ef19dcda4ac5",
      "f6ffb7c63cd442539f195b76acf151cd",
      "6b0ce77426bd4f228a735e982650f112",
      "0b900ef5da49448abcad401ae30a4581",
      "62c6cd2911a84a5fb68cc29a677f8447",
      "6626a87e22ca4896aa42a3d8d5ac1af6",
      "61f12553e88e4957acb98a42ba243055",
      "e972da65efa84a07b55727e5874a135d",
      "80283a0374004f88b84298288ce2721f",
      "6bca02a4166646ac8a2367f27d78b3b4",
      "e5fed59d58464136847950bc082a8582",
      "ad0b21b99938413bbf718515615de83f",
      "4571009c1d044b1cabfccacae2d54324",
      "719e04de88b44481803bae5528f16db0",
      "abfd9edd56324139bf68adf477ae3aa8",
      "6578c9eceff04f9299baac4dc0ee2e4d",
      "8cd1717e43544ce782c813747c3710c0",
      "655abcbe257546b0bdd632c293d35f46",
      "5b85c1223f7a4d8cae6517816b69cde0",
      "5c61ecf5043c406fbc58ebac247b95b6",
      "531def8a95274b5fb5b8829999a0d9ba",
      "511ce307ea704caab7a3d679df48517c",
      "1274a0ab6cae4241a0086d6446989dfb",
      "fd963f33e95c48d0b4afcb515d45ea68",
      "6ef6224bdf9746108984957bbd4ec80a",
      "f364b60772ca427a897a9f5b222a3ba0",
      "31e1965a4d674e6481a34ef95c06a748",
      "264acaffdb61454c85d3471c1206279d",
      "a967d43bbb7447f5b006b6329442209a",
      "2a83a818da0a4bef9c8caa88e9152307",
      "34862801faa5456aaddcfaf2393d4ec2",
      "a076ef212ac7457298510fa1ed96966c",
      "e0463944c46f407cbe100eb0c7d53643",
      "35229f3f031f43e1b23d6daea308f259",
      "77690ad55df043f9a0a788a868073fa6",
      "8ec39057b22d428ab49848bab5398572",
      "b238fd0ddc844cfe84431621152e272d",
      "095889547a634f27846145ec2ae8bd10",
      "54e9d0b428d24f0b9243c2bcd748967c",
      "2ea26c4a86804c73b5132955a589ac7d",
      "a56c147cec1e42568cdd4542942d9e24",
      "e702e41ecc754d058ea5540a25a83339",
      "cfdd7270b2c448ebb9b944bfc4bf68cf",
      "c08252b8dade45019ba62152efa88807",
      "9eae70486c764b3cb1311a3db4e45bce",
      "0a31d89619cc4b098c8d77fa8331ca80",
      "45d397148cec404985cc9cdca39bc268",
      "7d3dbe89bb214938b70d2314e2415cd7",
      "bdcc5e3301b042c99760383da21d9d0e",
      "e7fd233bc88f4f9eb471a61c39012da5",
      "7b3658b848f446ba9fe5f9551c38708b",
      "1d9fc43c6105402c98eb6c331baf11ad",
      "85ff432d245d476f999af207b5885367",
      "30c82000ec6046189a90aa6daa6bfcc8",
      "8c7fa331089c4a0ca71f4196f99f6d05",
      "561860e2da5b4dea9372418bae02d113",
      "3f34806e6f314ed4b5f2d4e5ec79b062",
      "488c143bb70c435d81977d8fd6950dd6",
      "0be43e5e47554cffb47224e7c6b222af",
      "578a7d3ccb1748fcb483a067c648f242",
      "42bac3c97cf94208b56280561300e370",
      "42200172192d475bbd2632bf1174c565",
      "a4b838f3ccfb48eb939e60ddb793e6e2",
      "46d8032335d64748b5ed65ec73d48e82",
      "148a6adff4294bf3a1cb47d85df4dec9"
     ]
    },
    "id": "-CTFP_GylS2a",
    "outputId": "bc875032-12e1-4000-8ea7-994f1688d196"
   },
   "outputs": [],
   "source": [
    "# Getting a CLIP style model to use as a reranker from Huggingface\n",
    "from transformers import pipeline\n",
    "\n",
    "#https://huggingface.co/openai/clip-vit-base-patch32?library=transformers\n",
    "classifier = pipeline(\"zero-shot-image-classification\", model=\"openai/clip-vit-large-patch14\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UN_SW8JZ4rhS"
   },
   "outputs": [],
   "source": [
    "def GX_get_image_urls(query, rerank_filter):\n",
    "    response = client.search.content(\n",
    "        id=bucket_id,\n",
    "        query=query\n",
    "    )\n",
    "\n",
    "    image_urls = set()\n",
    "\n",
    "    print(response.search.results)\n",
    "    print(len(response.search.results))\n",
    "    for semantic_object in response.search.results:\n",
    "        if 'multimodal_url' in dir(semantic_object):\n",
    "            image_urls.add(semantic_object.multimodal_url)\n",
    "        image_urls.update(semantic_object.page_images)\n",
    "\n",
    "    image_urls = list(image_urls)\n",
    "\n",
    "    ranked_results = classifier(\n",
    "        image_urls,\n",
    "        candidate_labels=rerank_filter,\n",
    "    )\n",
    "\n",
    "    #reformatting rank\n",
    "    for i in range(len(ranked_results)):\n",
    "        for j in range(len(rerank_filter)):\n",
    "            ranked_results[i][j]['url'] = image_urls[i]\n",
    "\n",
    "    #flattening\n",
    "    ranked_results = [x for xs in ranked_results for x in xs]\n",
    "\n",
    "    return ranked_results\n",
    "\n",
    "query = 'A diagram of the AI lifecycle'\n",
    "#creating a list of classes to compare to\n",
    "rerank_filters = [query, 'miscellaneous figure', 'miscellaneous page', 'miscellaneous table']\n",
    "\n",
    "ranked_results = GX_get_image_urls(query, rerank_filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 878
    },
    "id": "YfD4y7x95Jyq",
    "outputId": "b6dca40e-5a2d-4096-e3bd-0f25c804933e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_bcbac\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_bcbac_level0_col0\" class=\"col_heading level0 col0\" >score</th>\n",
       "      <th id=\"T_bcbac_level0_col1\" class=\"col_heading level0 col1\" >label</th>\n",
       "      <th id=\"T_bcbac_level0_col2\" class=\"col_heading level0 col2\" >url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_bcbac_level0_row0\" class=\"row_heading level0 row0\" >12</th>\n",
       "      <td id=\"T_bcbac_row0_col0\" class=\"data row0 col0\" >0.999999</td>\n",
       "      <td id=\"T_bcbac_row0_col1\" class=\"data row0 col1\" >A diagram of the AI lifecycle</td>\n",
       "      <td id=\"T_bcbac_row0_col2\" class=\"data row0 col2\" ><a target=\"_blank\" href=\"https://upload.eyelevel.ai/layout/raw/prod/d8606fc9-8be7-4bb1-b546-c8f2ba51b5e4/c4106c80-7a9d-4f3c-8b27-0b10aa9dd79c/figure-5-1.jpg\">https://upload.eyelevel.ai/layout/raw/prod/d8606fc9-8be7-4bb1-b546-c8f2ba51b5e4/c4106c80-7a9d-4f3c-8b27-0b10aa9dd79c/figure-5-1.jpg</a></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bcbac_level0_row1\" class=\"row_heading level0 row1\" >8</th>\n",
       "      <td id=\"T_bcbac_row1_col0\" class=\"data row1 col0\" >0.999997</td>\n",
       "      <td id=\"T_bcbac_row1_col1\" class=\"data row1 col1\" >A diagram of the AI lifecycle</td>\n",
       "      <td id=\"T_bcbac_row1_col2\" class=\"data row1 col2\" ><a target=\"_blank\" href=\"https://upload.eyelevel.ai/layout/raw/prod/d8606fc9-8be7-4bb1-b546-c8f2ba51b5e4/c4106c80-7a9d-4f3c-8b27-0b10aa9dd79c/figure-5-0.jpg\">https://upload.eyelevel.ai/layout/raw/prod/d8606fc9-8be7-4bb1-b546-c8f2ba51b5e4/c4106c80-7a9d-4f3c-8b27-0b10aa9dd79c/figure-5-0.jpg</a></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bcbac_level0_row2\" class=\"row_heading level0 row2\" >36</th>\n",
       "      <td id=\"T_bcbac_row2_col0\" class=\"data row2 col0\" >0.999929</td>\n",
       "      <td id=\"T_bcbac_row2_col1\" class=\"data row2 col1\" >A diagram of the AI lifecycle</td>\n",
       "      <td id=\"T_bcbac_row2_col2\" class=\"data row2 col2\" ><a target=\"_blank\" href=\"https://upload.eyelevel.ai/layout/raw/prod/d8606fc9-8be7-4bb1-b546-c8f2ba51b5e4/c4106c80-7a9d-4f3c-8b27-0b10aa9dd79c/figure-4-0.jpg\">https://upload.eyelevel.ai/layout/raw/prod/d8606fc9-8be7-4bb1-b546-c8f2ba51b5e4/c4106c80-7a9d-4f3c-8b27-0b10aa9dd79c/figure-4-0.jpg</a></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bcbac_level0_row3\" class=\"row_heading level0 row3\" >0</th>\n",
       "      <td id=\"T_bcbac_row3_col0\" class=\"data row3 col0\" >0.999839</td>\n",
       "      <td id=\"T_bcbac_row3_col1\" class=\"data row3 col1\" >A diagram of the AI lifecycle</td>\n",
       "      <td id=\"T_bcbac_row3_col2\" class=\"data row3 col2\" ><a target=\"_blank\" href=\"https://upload.eyelevel.ai/layout/raw/prod/d8606fc9-8be7-4bb1-b546-c8f2ba51b5e4/c4106c80-7a9d-4f3c-8b27-0b10aa9dd79c/figure-6-0.jpg\">https://upload.eyelevel.ai/layout/raw/prod/d8606fc9-8be7-4bb1-b546-c8f2ba51b5e4/c4106c80-7a9d-4f3c-8b27-0b10aa9dd79c/figure-6-0.jpg</a></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bcbac_level0_row4\" class=\"row_heading level0 row4\" >60</th>\n",
       "      <td id=\"T_bcbac_row4_col0\" class=\"data row4 col0\" >0.999330</td>\n",
       "      <td id=\"T_bcbac_row4_col1\" class=\"data row4 col1\" >A diagram of the AI lifecycle</td>\n",
       "      <td id=\"T_bcbac_row4_col2\" class=\"data row4 col2\" ><a target=\"_blank\" href=\"https://upload.eyelevel.ai/layout/raw/prod/d8606fc9-8be7-4bb1-b546-c8f2ba51b5e4/c4106c80-7a9d-4f3c-8b27-0b10aa9dd79c/1.jpg\">https://upload.eyelevel.ai/layout/raw/prod/d8606fc9-8be7-4bb1-b546-c8f2ba51b5e4/c4106c80-7a9d-4f3c-8b27-0b10aa9dd79c/1.jpg</a></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bcbac_level0_row5\" class=\"row_heading level0 row5\" >64</th>\n",
       "      <td id=\"T_bcbac_row5_col0\" class=\"data row5 col0\" >0.991700</td>\n",
       "      <td id=\"T_bcbac_row5_col1\" class=\"data row5 col1\" >A diagram of the AI lifecycle</td>\n",
       "      <td id=\"T_bcbac_row5_col2\" class=\"data row5 col2\" ><a target=\"_blank\" href=\"https://upload.eyelevel.ai/layout/raw/prod/d8606fc9-8be7-4bb1-b546-c8f2ba51b5e4/c4106c80-7a9d-4f3c-8b27-0b10aa9dd79c/5.jpg\">https://upload.eyelevel.ai/layout/raw/prod/d8606fc9-8be7-4bb1-b546-c8f2ba51b5e4/c4106c80-7a9d-4f3c-8b27-0b10aa9dd79c/5.jpg</a></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bcbac_level0_row6\" class=\"row_heading level0 row6\" >40</th>\n",
       "      <td id=\"T_bcbac_row6_col0\" class=\"data row6 col0\" >0.982985</td>\n",
       "      <td id=\"T_bcbac_row6_col1\" class=\"data row6 col1\" >A diagram of the AI lifecycle</td>\n",
       "      <td id=\"T_bcbac_row6_col2\" class=\"data row6 col2\" ><a target=\"_blank\" href=\"https://upload.eyelevel.ai/layout/raw/prod/d8606fc9-8be7-4bb1-b546-c8f2ba51b5e4/c4106c80-7a9d-4f3c-8b27-0b10aa9dd79c/table-4-0.jpg\">https://upload.eyelevel.ai/layout/raw/prod/d8606fc9-8be7-4bb1-b546-c8f2ba51b5e4/c4106c80-7a9d-4f3c-8b27-0b10aa9dd79c/table-4-0.jpg</a></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bcbac_level0_row7\" class=\"row_heading level0 row7\" >24</th>\n",
       "      <td id=\"T_bcbac_row7_col0\" class=\"data row7 col0\" >0.974595</td>\n",
       "      <td id=\"T_bcbac_row7_col1\" class=\"data row7 col1\" >A diagram of the AI lifecycle</td>\n",
       "      <td id=\"T_bcbac_row7_col2\" class=\"data row7 col2\" ><a target=\"_blank\" href=\"https://upload.eyelevel.ai/layout/raw/prod/d8606fc9-8be7-4bb1-b546-c8f2ba51b5e4/c4106c80-7a9d-4f3c-8b27-0b10aa9dd79c/figure-8-0.jpg\">https://upload.eyelevel.ai/layout/raw/prod/d8606fc9-8be7-4bb1-b546-c8f2ba51b5e4/c4106c80-7a9d-4f3c-8b27-0b10aa9dd79c/figure-8-0.jpg</a></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bcbac_level0_row8\" class=\"row_heading level0 row8\" >4</th>\n",
       "      <td id=\"T_bcbac_row8_col0\" class=\"data row8 col0\" >0.965495</td>\n",
       "      <td id=\"T_bcbac_row8_col1\" class=\"data row8 col1\" >A diagram of the AI lifecycle</td>\n",
       "      <td id=\"T_bcbac_row8_col2\" class=\"data row8 col2\" ><a target=\"_blank\" href=\"https://upload.eyelevel.ai/layout/raw/prod/d8606fc9-8be7-4bb1-b546-c8f2ba51b5e4/c4106c80-7a9d-4f3c-8b27-0b10aa9dd79c/2.jpg\">https://upload.eyelevel.ai/layout/raw/prod/d8606fc9-8be7-4bb1-b546-c8f2ba51b5e4/c4106c80-7a9d-4f3c-8b27-0b10aa9dd79c/2.jpg</a></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bcbac_level0_row9\" class=\"row_heading level0 row9\" >20</th>\n",
       "      <td id=\"T_bcbac_row9_col0\" class=\"data row9 col0\" >0.942037</td>\n",
       "      <td id=\"T_bcbac_row9_col1\" class=\"data row9 col1\" >A diagram of the AI lifecycle</td>\n",
       "      <td id=\"T_bcbac_row9_col2\" class=\"data row9 col2\" ><a target=\"_blank\" href=\"https://upload.eyelevel.ai/layout/raw/prod/d8606fc9-8be7-4bb1-b546-c8f2ba51b5e4/c4106c80-7a9d-4f3c-8b27-0b10aa9dd79c/table-4-1.jpg\">https://upload.eyelevel.ai/layout/raw/prod/d8606fc9-8be7-4bb1-b546-c8f2ba51b5e4/c4106c80-7a9d-4f3c-8b27-0b10aa9dd79c/table-4-1.jpg</a></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bcbac_level0_row10\" class=\"row_heading level0 row10\" >44</th>\n",
       "      <td id=\"T_bcbac_row10_col0\" class=\"data row10 col0\" >0.938895</td>\n",
       "      <td id=\"T_bcbac_row10_col1\" class=\"data row10 col1\" >A diagram of the AI lifecycle</td>\n",
       "      <td id=\"T_bcbac_row10_col2\" class=\"data row10 col2\" ><a target=\"_blank\" href=\"https://upload.eyelevel.ai/layout/raw/prod/d8606fc9-8be7-4bb1-b546-c8f2ba51b5e4/c4106c80-7a9d-4f3c-8b27-0b10aa9dd79c/8.jpg\">https://upload.eyelevel.ai/layout/raw/prod/d8606fc9-8be7-4bb1-b546-c8f2ba51b5e4/c4106c80-7a9d-4f3c-8b27-0b10aa9dd79c/8.jpg</a></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bcbac_level0_row11\" class=\"row_heading level0 row11\" >28</th>\n",
       "      <td id=\"T_bcbac_row11_col0\" class=\"data row11 col0\" >0.908298</td>\n",
       "      <td id=\"T_bcbac_row11_col1\" class=\"data row11 col1\" >A diagram of the AI lifecycle</td>\n",
       "      <td id=\"T_bcbac_row11_col2\" class=\"data row11 col2\" ><a target=\"_blank\" href=\"https://upload.eyelevel.ai/layout/raw/prod/d8606fc9-8be7-4bb1-b546-c8f2ba51b5e4/c4106c80-7a9d-4f3c-8b27-0b10aa9dd79c/3.jpg\">https://upload.eyelevel.ai/layout/raw/prod/d8606fc9-8be7-4bb1-b546-c8f2ba51b5e4/c4106c80-7a9d-4f3c-8b27-0b10aa9dd79c/3.jpg</a></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bcbac_level0_row12\" class=\"row_heading level0 row12\" >17</th>\n",
       "      <td id=\"T_bcbac_row12_col0\" class=\"data row12 col0\" >0.167604</td>\n",
       "      <td id=\"T_bcbac_row12_col1\" class=\"data row12 col1\" >A diagram of the AI lifecycle</td>\n",
       "      <td id=\"T_bcbac_row12_col2\" class=\"data row12 col2\" ><a target=\"_blank\" href=\"https://upload.eyelevel.ai/layout/raw/prod/d8606fc9-8be7-4bb1-b546-c8f2ba51b5e4/c4106c80-7a9d-4f3c-8b27-0b10aa9dd79c/7.jpg\">https://upload.eyelevel.ai/layout/raw/prod/d8606fc9-8be7-4bb1-b546-c8f2ba51b5e4/c4106c80-7a9d-4f3c-8b27-0b10aa9dd79c/7.jpg</a></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bcbac_level0_row13\" class=\"row_heading level0 row13\" >33</th>\n",
       "      <td id=\"T_bcbac_row13_col0\" class=\"data row13 col0\" >0.036854</td>\n",
       "      <td id=\"T_bcbac_row13_col1\" class=\"data row13 col1\" >A diagram of the AI lifecycle</td>\n",
       "      <td id=\"T_bcbac_row13_col2\" class=\"data row13 col2\" ><a target=\"_blank\" href=\"https://upload.eyelevel.ai/layout/raw/prod/d8606fc9-8be7-4bb1-b546-c8f2ba51b5e4/c4106c80-7a9d-4f3c-8b27-0b10aa9dd79c/4.jpg\">https://upload.eyelevel.ai/layout/raw/prod/d8606fc9-8be7-4bb1-b546-c8f2ba51b5e4/c4106c80-7a9d-4f3c-8b27-0b10aa9dd79c/4.jpg</a></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bcbac_level0_row14\" class=\"row_heading level0 row14\" >57</th>\n",
       "      <td id=\"T_bcbac_row14_col0\" class=\"data row14 col0\" >0.011834</td>\n",
       "      <td id=\"T_bcbac_row14_col1\" class=\"data row14 col1\" >A diagram of the AI lifecycle</td>\n",
       "      <td id=\"T_bcbac_row14_col2\" class=\"data row14 col2\" ><a target=\"_blank\" href=\"https://upload.eyelevel.ai/layout/raw/prod/d8606fc9-8be7-4bb1-b546-c8f2ba51b5e4/c4106c80-7a9d-4f3c-8b27-0b10aa9dd79c/6.jpg\">https://upload.eyelevel.ai/layout/raw/prod/d8606fc9-8be7-4bb1-b546-c8f2ba51b5e4/c4106c80-7a9d-4f3c-8b27-0b10aa9dd79c/6.jpg</a></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bcbac_level0_row15\" class=\"row_heading level0 row15\" >50</th>\n",
       "      <td id=\"T_bcbac_row15_col0\" class=\"data row15 col0\" >0.001227</td>\n",
       "      <td id=\"T_bcbac_row15_col1\" class=\"data row15 col1\" >A diagram of the AI lifecycle</td>\n",
       "      <td id=\"T_bcbac_row15_col2\" class=\"data row15 col2\" ><a target=\"_blank\" href=\"https://upload.eyelevel.ai/layout/raw/prod/d8606fc9-8be7-4bb1-b546-c8f2ba51b5e4/c4106c80-7a9d-4f3c-8b27-0b10aa9dd79c/9.jpg\">https://upload.eyelevel.ai/layout/raw/prod/d8606fc9-8be7-4bb1-b546-c8f2ba51b5e4/c4106c80-7a9d-4f3c-8b27-0b10aa9dd79c/9.jpg</a></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bcbac_level0_row16\" class=\"row_heading level0 row16\" >55</th>\n",
       "      <td id=\"T_bcbac_row16_col0\" class=\"data row16 col0\" >0.000032</td>\n",
       "      <td id=\"T_bcbac_row16_col1\" class=\"data row16 col1\" >A diagram of the AI lifecycle</td>\n",
       "      <td id=\"T_bcbac_row16_col2\" class=\"data row16 col2\" ><a target=\"_blank\" href=\"https://upload.eyelevel.ai/layout/raw/prod/d8606fc9-8be7-4bb1-b546-c8f2ba51b5e4/c4106c80-7a9d-4f3c-8b27-0b10aa9dd79c/10.jpg\">https://upload.eyelevel.ai/layout/raw/prod/d8606fc9-8be7-4bb1-b546-c8f2ba51b5e4/c4106c80-7a9d-4f3c-8b27-0b10aa9dd79c/10.jpg</a></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7c777c8b73d0>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(ranked_results)\n",
    "df = df[df['label'] == query].sort_values('score',ascending=False)\n",
    "\n",
    "def make_clickable(val):\n",
    "    # target _blank to open new window\n",
    "    return '<a target=\"_blank\" href=\"{}\">{}</a>'.format(val, val)\n",
    "\n",
    "df.style.format({'url': make_clickable})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b5gPwrt4CNrn"
   },
   "source": [
    "As can be seen, the top responses are figures which are most relevent to the query."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0453cd0618de4e55948be081b3caa50f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_13fbc9ac68264948904524f8838e2809",
      "placeholder": "​",
      "style": "IPY_MODEL_307091e60cbd4347a2c5ca282d62b5e4",
      "value": "model.safetensors: 100%"
     }
    },
    "095889547a634f27846145ec2ae8bd10": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0a31d89619cc4b098c8d77fa8331ca80": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7b3658b848f446ba9fe5f9551c38708b",
      "max": 389,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1d9fc43c6105402c98eb6c331baf11ad",
      "value": 389
     }
    },
    "0b900ef5da49448abcad401ae30a4581": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0be43e5e47554cffb47224e7c6b222af": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "11c1e0d6f6fe4821a0de19c33aae87f7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1274a0ab6cae4241a0086d6446989dfb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_31e1965a4d674e6481a34ef95c06a748",
      "placeholder": "​",
      "style": "IPY_MODEL_264acaffdb61454c85d3471c1206279d",
      "value": "merges.txt: 100%"
     }
    },
    "13fbc9ac68264948904524f8838e2809": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "148a6adff4294bf3a1cb47d85df4dec9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1d9fc43c6105402c98eb6c331baf11ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2251e6ecb6594da7a40e815281c371b8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "264acaffdb61454c85d3471c1206279d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2a83a818da0a4bef9c8caa88e9152307": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2de01ad7eef2491dbdb38fac20586247": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ef7f99718dc040eb9632e7a399c91aaa",
       "IPY_MODEL_4ea89bf3cc4c43f8874efb789942411a",
       "IPY_MODEL_82f17ba5f8b646ee879566628df86101"
      ],
      "layout": "IPY_MODEL_dd5deaa200eb462e957bd3bfe18cd4c8"
     }
    },
    "2ea26c4a86804c73b5132955a589ac7d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "307091e60cbd4347a2c5ca282d62b5e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "30c82000ec6046189a90aa6daa6bfcc8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "31e1965a4d674e6481a34ef95c06a748": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "34862801faa5456aaddcfaf2393d4ec2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "35229f3f031f43e1b23d6daea308f259": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_095889547a634f27846145ec2ae8bd10",
      "placeholder": "​",
      "style": "IPY_MODEL_54e9d0b428d24f0b9243c2bcd748967c",
      "value": "tokenizer.json: 100%"
     }
    },
    "3f34806e6f314ed4b5f2d4e5ec79b062": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_42200172192d475bbd2632bf1174c565",
      "max": 316,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a4b838f3ccfb48eb939e60ddb793e6e2",
      "value": 316
     }
    },
    "42200172192d475bbd2632bf1174c565": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "42bac3c97cf94208b56280561300e370": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4571009c1d044b1cabfccacae2d54324": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_655abcbe257546b0bdd632c293d35f46",
      "max": 961143,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5b85c1223f7a4d8cae6517816b69cde0",
      "value": 961143
     }
    },
    "45d397148cec404985cc9cdca39bc268": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_85ff432d245d476f999af207b5885367",
      "placeholder": "​",
      "style": "IPY_MODEL_30c82000ec6046189a90aa6daa6bfcc8",
      "value": " 389/389 [00:00&lt;00:00, 17.4kB/s]"
     }
    },
    "46d8032335d64748b5ed65ec73d48e82": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "488c143bb70c435d81977d8fd6950dd6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_46d8032335d64748b5ed65ec73d48e82",
      "placeholder": "​",
      "style": "IPY_MODEL_148a6adff4294bf3a1cb47d85df4dec9",
      "value": " 316/316 [00:00&lt;00:00, 10.3kB/s]"
     }
    },
    "4ea89bf3cc4c43f8874efb789942411a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b2461ed08acb4a1687be8f12e7e9f6b6",
      "max": 4519,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8068671318464f1ea2670fad0ebaebda",
      "value": 4519
     }
    },
    "511ce307ea704caab7a3d679df48517c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1274a0ab6cae4241a0086d6446989dfb",
       "IPY_MODEL_fd963f33e95c48d0b4afcb515d45ea68",
       "IPY_MODEL_6ef6224bdf9746108984957bbd4ec80a"
      ],
      "layout": "IPY_MODEL_f364b60772ca427a897a9f5b222a3ba0"
     }
    },
    "529a3de1631342d2a2ce854b0ea7937b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0453cd0618de4e55948be081b3caa50f",
       "IPY_MODEL_b9ce3f1bafd54c0fa6d625560d3e365d",
       "IPY_MODEL_e64bfa90d3294e31ad2ab09fe2d71164"
      ],
      "layout": "IPY_MODEL_2251e6ecb6594da7a40e815281c371b8"
     }
    },
    "531def8a95274b5fb5b8829999a0d9ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "54e9d0b428d24f0b9243c2bcd748967c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "561860e2da5b4dea9372418bae02d113": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_578a7d3ccb1748fcb483a067c648f242",
      "placeholder": "​",
      "style": "IPY_MODEL_42bac3c97cf94208b56280561300e370",
      "value": "preprocessor_config.json: 100%"
     }
    },
    "578a7d3ccb1748fcb483a067c648f242": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5b85c1223f7a4d8cae6517816b69cde0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5c61ecf5043c406fbc58ebac247b95b6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "61f12553e88e4957acb98a42ba243055": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "62c6cd2911a84a5fb68cc29a677f8447": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "655abcbe257546b0bdd632c293d35f46": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6578c9eceff04f9299baac4dc0ee2e4d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6626a87e22ca4896aa42a3d8d5ac1af6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6b0ce77426bd4f228a735e982650f112": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_80283a0374004f88b84298288ce2721f",
      "placeholder": "​",
      "style": "IPY_MODEL_6bca02a4166646ac8a2367f27d78b3b4",
      "value": " 905/905 [00:00&lt;00:00, 44.6kB/s]"
     }
    },
    "6bca02a4166646ac8a2367f27d78b3b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6ef6224bdf9746108984957bbd4ec80a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_34862801faa5456aaddcfaf2393d4ec2",
      "placeholder": "​",
      "style": "IPY_MODEL_a076ef212ac7457298510fa1ed96966c",
      "value": " 525k/525k [00:00&lt;00:00, 16.0MB/s]"
     }
    },
    "719e04de88b44481803bae5528f16db0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5c61ecf5043c406fbc58ebac247b95b6",
      "placeholder": "​",
      "style": "IPY_MODEL_531def8a95274b5fb5b8829999a0d9ba",
      "value": " 961k/961k [00:00&lt;00:00, 12.2MB/s]"
     }
    },
    "72f717b1bf0f40978a44ef19dcda4ac5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_62c6cd2911a84a5fb68cc29a677f8447",
      "placeholder": "​",
      "style": "IPY_MODEL_6626a87e22ca4896aa42a3d8d5ac1af6",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "77690ad55df043f9a0a788a868073fa6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2ea26c4a86804c73b5132955a589ac7d",
      "max": 2224003,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a56c147cec1e42568cdd4542942d9e24",
      "value": 2224003
     }
    },
    "7b3658b848f446ba9fe5f9551c38708b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7d3dbe89bb214938b70d2314e2415cd7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "80283a0374004f88b84298288ce2721f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8068671318464f1ea2670fad0ebaebda": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "82f17ba5f8b646ee879566628df86101": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b143e1f08fb74385be4994ba372f64ec",
      "placeholder": "​",
      "style": "IPY_MODEL_c6fad28c4d9241f9b200165ce6de3641",
      "value": " 4.52k/4.52k [00:00&lt;00:00, 76.8kB/s]"
     }
    },
    "85ff432d245d476f999af207b5885367": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8bba39017c3e4d678cb7ab41102decde": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8c7fa331089c4a0ca71f4196f99f6d05": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_561860e2da5b4dea9372418bae02d113",
       "IPY_MODEL_3f34806e6f314ed4b5f2d4e5ec79b062",
       "IPY_MODEL_488c143bb70c435d81977d8fd6950dd6"
      ],
      "layout": "IPY_MODEL_0be43e5e47554cffb47224e7c6b222af"
     }
    },
    "8cd1717e43544ce782c813747c3710c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8ec39057b22d428ab49848bab5398572": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e702e41ecc754d058ea5540a25a83339",
      "placeholder": "​",
      "style": "IPY_MODEL_cfdd7270b2c448ebb9b944bfc4bf68cf",
      "value": " 2.22M/2.22M [00:00&lt;00:00, 29.4MB/s]"
     }
    },
    "95339a33915b480a9a8caf8f9fc05a7e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9eae70486c764b3cb1311a3db4e45bce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bdcc5e3301b042c99760383da21d9d0e",
      "placeholder": "​",
      "style": "IPY_MODEL_e7fd233bc88f4f9eb471a61c39012da5",
      "value": "special_tokens_map.json: 100%"
     }
    },
    "a076ef212ac7457298510fa1ed96966c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a4b838f3ccfb48eb939e60ddb793e6e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a56c147cec1e42568cdd4542942d9e24": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a967d43bbb7447f5b006b6329442209a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "abfd9edd56324139bf68adf477ae3aa8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ad0b21b99938413bbf718515615de83f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6578c9eceff04f9299baac4dc0ee2e4d",
      "placeholder": "​",
      "style": "IPY_MODEL_8cd1717e43544ce782c813747c3710c0",
      "value": "vocab.json: 100%"
     }
    },
    "b143e1f08fb74385be4994ba372f64ec": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b238fd0ddc844cfe84431621152e272d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b2461ed08acb4a1687be8f12e7e9f6b6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b9ce3f1bafd54c0fa6d625560d3e365d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_11c1e0d6f6fe4821a0de19c33aae87f7",
      "max": 1710540580,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bc63f2535ffd4b7cae744c998b557fb2",
      "value": 1710540580
     }
    },
    "bc63f2535ffd4b7cae744c998b557fb2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "bdcc5e3301b042c99760383da21d9d0e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c08252b8dade45019ba62152efa88807": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9eae70486c764b3cb1311a3db4e45bce",
       "IPY_MODEL_0a31d89619cc4b098c8d77fa8331ca80",
       "IPY_MODEL_45d397148cec404985cc9cdca39bc268"
      ],
      "layout": "IPY_MODEL_7d3dbe89bb214938b70d2314e2415cd7"
     }
    },
    "c6fad28c4d9241f9b200165ce6de3641": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cfdd7270b2c448ebb9b944bfc4bf68cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d8b3ae97e6b5436d9b91db60350cc817": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "da071879235a42bd8651bec7fa6b607b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_72f717b1bf0f40978a44ef19dcda4ac5",
       "IPY_MODEL_f6ffb7c63cd442539f195b76acf151cd",
       "IPY_MODEL_6b0ce77426bd4f228a735e982650f112"
      ],
      "layout": "IPY_MODEL_0b900ef5da49448abcad401ae30a4581"
     }
    },
    "dd5deaa200eb462e957bd3bfe18cd4c8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e0463944c46f407cbe100eb0c7d53643": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_35229f3f031f43e1b23d6daea308f259",
       "IPY_MODEL_77690ad55df043f9a0a788a868073fa6",
       "IPY_MODEL_8ec39057b22d428ab49848bab5398572"
      ],
      "layout": "IPY_MODEL_b238fd0ddc844cfe84431621152e272d"
     }
    },
    "e5fed59d58464136847950bc082a8582": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ad0b21b99938413bbf718515615de83f",
       "IPY_MODEL_4571009c1d044b1cabfccacae2d54324",
       "IPY_MODEL_719e04de88b44481803bae5528f16db0"
      ],
      "layout": "IPY_MODEL_abfd9edd56324139bf68adf477ae3aa8"
     }
    },
    "e64bfa90d3294e31ad2ab09fe2d71164": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f3ef2611d917486b89f77574e5670941",
      "placeholder": "​",
      "style": "IPY_MODEL_95339a33915b480a9a8caf8f9fc05a7e",
      "value": " 1.71G/1.71G [00:25&lt;00:00, 120MB/s]"
     }
    },
    "e702e41ecc754d058ea5540a25a83339": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e7fd233bc88f4f9eb471a61c39012da5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e972da65efa84a07b55727e5874a135d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ef7f99718dc040eb9632e7a399c91aaa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8bba39017c3e4d678cb7ab41102decde",
      "placeholder": "​",
      "style": "IPY_MODEL_d8b3ae97e6b5436d9b91db60350cc817",
      "value": "config.json: 100%"
     }
    },
    "f364b60772ca427a897a9f5b222a3ba0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f3ef2611d917486b89f77574e5670941": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f6ffb7c63cd442539f195b76acf151cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_61f12553e88e4957acb98a42ba243055",
      "max": 905,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e972da65efa84a07b55727e5874a135d",
      "value": 905
     }
    },
    "fd963f33e95c48d0b4afcb515d45ea68": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a967d43bbb7447f5b006b6329442209a",
      "max": 524619,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2a83a818da0a4bef9c8caa88e9152307",
      "value": 524619
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
